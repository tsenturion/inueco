# Работа с сетью: асинхронные HTTP‑клиенты и устойчивые WebSocket‑подключения

Тема: **httpx**, **aiohttp**, таймауты, пулы соединений, повторные подключения и структурная конкурентность.
Python 3.11+

---

##  httpx.AsyncClient: базовый GET с фазовыми таймаутами

```python
import asyncio
import httpx

REQUEST_TIMEOUT = httpx.Timeout(connect=2.0, read=5.0, write=5.0, pool=2.0)

async def main() -> None:
    async with httpx.AsyncClient(timeout=REQUEST_TIMEOUT) as client:
        r = await client.get("https://api.example.com/v1/status")
        r.raise_for_status()
        print(r.json())

if __name__ == "__main__":
    asyncio.run(main())
```

**Описание:** Описание: Фазовые таймауты позволяют детально контролировать жизненный цикл запроса: сколько ждём установку TCP/TLS (connect), сколько отдаём на запись запроса (write), сколько ждём первый и последующие байты ответа (read) и как долго согласны ждать свободное соединение из пула (pool). Такой разбор помогает быстро локализовать, где именно «вязнет» клиент — при установке соединения, в бэкенде апстрима или в контеншене пула.

На практике имеет смысл начинать с умеренно строгих значений (например, connect=1–2s, read=3–5s) и затем калибровать их по метрикам/логам. Для критичных путей добавляйте бизнес‑дедлайн поверх (см. пример 4). Исключения различаются по фазам (ConnectTimeout, ReadTimeout, PoolTimeout/TimeoutException) — обрабатывайте их по‑разному в ретраях и алертах, иначе рискуете скрыть реальные проблемы с инфраструктурой.

---

## Переиспользование клиента и явное закрытие

```python
import asyncio
import httpx

class HttpClient:

    def __init__(self) -> None:
        self._client = httpx.AsyncClient()

    async def get_json(self, url: str) -> dict:
        r = await self._client.get(url)
        r.raise_for_status()
        return r.json()

    async def close(self) -> None:
        await self._client.aclose()

async def main():
    client = HttpClient()
    try:
        print(await client.get_json('https://api.example.com/v1/info'))
    finally:
        await client.close()
asyncio.run(main())
```

**Описание:** Создание одного AsyncClient на процесс/компонент даёт реальный выигрыш: TCP/TLS‑handshake, ALPN и сертификация выполняются реже, а keep‑alive/HTTP‑2 канал сохраняется между вызовами. Это снижает латентность и нагрузку на апстримы и балансировщики.

Важно корректно закрывать клиент в `finally/atexit/хуках` жизненного цикла сервиса. Протечки клиентов приводят к зомби‑соединениям и исчерпанию файловых дескрипторов. В DI-контейнерах держите клиент как singleton, а в тестах — используйте фикстуры, закрывающие его после выполнения набора кейсов.

---

## Лимиты пула и HTTP/2 в httpx

```python
import asyncio
import httpx
POOL = httpx.Limits(max_connections=200, max_keepalive_connections=50)

async def main():
    async with httpx.AsyncClient(limits=POOL, http2=True) as client:
        r = await client.get('https://api.example.com/v2/items')
        r.raise_for_status()
        print(r.http_version, len(r.content))
asyncio.run(main())
```

**Описание:** Лимит max_connections защищает апстрим и ваш процесс от всплесков конкурентных запросов; max_keepalive_connections удерживает разумный «горячий» пул, не распухая до сотен простаивающих сокетов. Подбирайте значения под реальные профили трафика, не забывая о `ulimit/epoll` и лимитах балансировщика.

HTTP/2 при поддержке сервера даёт мультиплексирование по одному TCP‑соединению, экономит handshakes и уменьшает `head‑of‑line` `blocking` на уровне приложений. Но следите за `flow‑control` и настройками сервера: при чрезмерных параллельных стримах вы можете упереться в лимиты окна или приоритизацию, что схлопнет выгоду.

---

## Общий операционный дедлайн поверх транспортных таймаутов

```python
import asyncio
import httpx

async def fetch_with_deadline(client: httpx.AsyncClient, url: str) -> bytes:
    async with asyncio.timeout(6.0):  # общий предел на операцию
        r = await client.get(url, timeout=httpx.Timeout(connect=2.0, read=5.0))
    r.raise_for_status()
    return r.content
```

**Описание:** Транспортные таймауты контролируют фазы I/O, но бизнес‑операция часто включает больше шагов (подготовка, несколько запросов, сериализация). Внешний `asyncio.timeout()` гарантирует, что вся операция укладывается в бюджет — важный механизм для предсказуемых SLA.

Различайте CancelledError внутри и `TimeoutError` снаружи: корректная обработка позволяет аккуратно отменять подзадачи, освобождать ресурсы и эмитить метрики «по вине дедлайна», а не маскировать таймауты под общие «ошибки сети». В цепочках RPC прокидывайте остаток дедлайна дальше (deadline propagation).

---

## Повторы с экспоненциальным backoff и джиттером (идемпотентные операции)

```python
import asyncio, random, httpx

async def get_with_retry(client: httpx.AsyncClient, url: str, attempts: int = 3) -> httpx.Response:
    base = 0.2
    for i in range(1, attempts + 1):
        try:
            r = await client.get(url)
            r.raise_for_status()
            return r
        except (httpx.ConnectError, httpx.ReadTimeout, httpx.RemoteProtocolError):
            if i == attempts:
                raise
            delay = min(base * (2 ** (i - 1)) + random.uniform(0.0, base), 5.0)
            await asyncio.sleep(delay)
```

**Описание:** Ретраи повышают успех при кратковременных сетевых сбоях, рестартах и балансировке. Экспоненциальный backoff с джиттером устраняет «толчки стада» (thundering herd), равномерно распределяя повторные попытки по времени.

Ретрайте только идемпотентные методы (GET/HEAD/PUT/DELETE) и только на транзиентные ошибки. Для POST используйте идемпотентные ключи или outbox/сага‑паттерны. Логируйте финальные неудачи отдельной меткой (например, retry_exhausted=true) — так проще находить проблемные апстримы.

---

## Ограничение параллелизма через Semaphore и обработка «по мере готовности»

```python
import asyncio, httpx

async def batch_get(urls: list[str], concurrency: int = 50) -> list[tuple[str, int]]:
    sem = asyncio.Semaphore(concurrency)
    async with httpx.AsyncClient() as client:
        async def one(u: str) -> tuple[str, int]:
            async with sem:
                r = await client.get(u)
                r.raise_for_status()
                return u, r.status_code

        tasks = [asyncio.create_task(one(u)) for u in urls]
        results: list[tuple[str, int]] = []
        for fut in asyncio.as_completed(tasks):
            try:
                results.append(await fut)
            except Exception:
                results.append(("error", -1))
        return results
```

**Описание:** Даже с лимитами пула вы можете перегрузить апстрим бурстом задач. Семафор даёт явный потолок «активных I/O», сохраняя предсказуемое использование CPU/FD и защищая апстримы.

`as_completed` снижает TTFB агрегированной операции: вы начинаете обрабатывать первые результаты, пока остальные ещё выполняются. Это упрощает деградацию — можно отдавать частичные ответы, динамически уменьшать concurrency и изолировать плохие хосты.

---

## Потоковая загрузка с ограничением памяти (httpx.stream)

```python
import httpx

async def stream_to_file(url: str, path: str, chunk: int = 64 * 1024) -> None:
    async with httpx.AsyncClient() as c:
        async with c.stream("GET", url) as r:
            r.raise_for_status()
            with open(path, "wb") as f:
                async for part in r.aiter_bytes(chunk_size=chunk):
                    f.write(part)
```

**Описание:** Стриминг позволяет скачивать десятки гигабайт без раздувания RSS. Подбирайте chunk_size под файловую систему и сеть: маленькие куски увеличивают системные вызовы, большие — буферизацию и пиковую память.

Добавляйте контроль скорости/времени (rate‑limit, общий дедлайн) и валидацию контента: размер из Content-Length, хэш/подпись, минимальные скорости чтения. Для временных файлов используйте atomic‑rename — это защитит читателей от частично записанных артефактов.
---

## Настройка транспорта в aiohttp: лимиты и DNS‑кэш

```python
import asyncio, aiohttp

connector = aiohttp.TCPConnector(limit=200, limit_per_host=50, ttl_dns_cache=300)
timeout = aiohttp.ClientTimeout(total=None, connect=2.0, sock_connect=2.0, sock_read=5.0)

async def fetch_json(url: str) -> dict:
    async with aiohttp.ClientSession(connector=connector) as s:
        async with asyncio.timeout(6.0):
            async with s.get(url, timeout=timeout) as resp:
                resp.raise_for_status()
                return await resp.json()
```

**Описание:** `limit` и `limit_per_host` помогают не «забить» единичный апстрим и не исчерпать локальные ресурсы. `ttl_dns_cache` сокращает DNS‑резолвы, но оставляйте его короче TTL записи у провайдера или балансировщика, иначе потеряете обновления адресов.

Разделяйте коннекторы для разных профилей трафика (внутренний/внешний), если им нужны разные лимиты и прокси. ClientTimeout(total=None, …) позволяет управлять фазами отдельно и не даёт «ложного общего таймаута», который часто маскирует медленные чтения.

---

## Загрузка больших ответов с ограничением размера

```python
import httpx
MAX_BYTES = 5 * 1024 * 1024  # 5 MiB

async def get_capped(url: str) -> bytes:
    async with httpx.AsyncClient() as c:
        async with c.stream("GET", url) as r:
            r.raise_for_status()
            buf = bytearray()
            async for chunk in r.aiter_bytes():
                buf += chunk
                if len(buf) > MAX_BYTES:
                    raise ValueError("response too large")
            return bytes(buf)
```

**Описание:** «Крышка» на размер защищает от злоумышленников и ошибочно сконфигурированных сервисов. Даже если сервер не прислал `Content-Length`, вы не съедите всю память.

Для JSON/текстов имеет смысл ещё и ограничивать размер строки/объекта при десериализации. При ожидании крупных ответов — наоборот, используйте потоковый парсинг (например, ijson/стрим‑NDJSON) и пишите на диск/в объектное хранилище, не в память.

---

## Прокси и пользовательский TLS‑контекст

```python
import asyncio, httpx, ssl

async def main():
    ctx = ssl.create_default_context()
    ctx.minimum_version = ssl.TLSVersion.TLSv1_2
    async with httpx.AsyncClient(verify=ctx, proxies='http://proxy.local:3128') as client:
        r = await client.get('https://secure.example.com/')
        r.raise_for_status()
        print(r.http_version)
asyncio.run(main())
```

**Описание:** Собственный SSLContext позволяет закрепить минимальные версии TLS, наборы шифров и доверенные CA/Pinning. В корпоративной среде часто требуется свой CA или MITM‑прокси — явная передача контекста делает поведение детерминированным и наблюдаемым.

Следите за валидацией хостнейма и актуальностью корневых сертификатов. Для прокси учитывайте аутентификацию, списки исключений (no_proxy) и политику CONNECT для HTTPS. Логируйте ALPN и конечную версию протокола — это помогает ловить странные понижения до HTTP/1.1.
---

## Наблюдаемость в httpx: event hooks

```python
import httpx

async def on_response(resp: httpx.Response):
    metrics_observe('http_client_latency_seconds', resp.elapsed.total_seconds(), {'code': str(resp.status_code)})
async with httpx.AsyncClient(event_hooks={'response': [on_response]}) as c:
    await c.get('https://api.example.com/health')
```

**Описание:** Хуки позволяют без обёрток внедрять метрики, трассировки и логирование. Записывайте латентность, размер тела, основные заголовки (cache‑hit, backend‑host) и ретрай‑теги — так вы увидите реальную картину SLO.

Для продвинутой наблюдаемости добавляйте correlation‑ID в заголовки, связывайте с трассировкой (OpenTelemetry), а ошибки помечайте причинами (DNS, connect, TLS, read). Старайтесь не блокировать хук — тяжёлые операции отправляйте в неблокирующую очередь.

---

## Базовый WebSocket‑клиент с heartbeat (aiohttp)

```python
import asyncio, aiohttp
PING_INTERVAL = 10.0

async def ws_client(url: str):
    async with aiohttp.ClientSession() as s:
        async with s.ws_connect(url, heartbeat=PING_INTERVAL) as ws:
            async for msg in ws:
                if msg.type == aiohttp.WSMsgType.TEXT:
                    handle(msg.data)
                elif msg.type in (aiohttp.WSMsgType.CLOSE, aiohttp.WSMsgType.ERROR):
                    break
asyncio.run(ws_client('wss://stream.example.com/v1/events'))
```

**Описание:** `Периодический ping/pong помогает вовремя обнаруживать оборванные TCP/NAT‑сессии, фаерволы с неактивностью и подвисшие прокси. Это ключ к устойчивым длительным подключениям.

Выставляйте интервал чуть меньше сетевых таймаутов/идл‑квот балансировщика. Обрабатывайте `CLOSE` с кодами/причинами сервера — по ним можно принимать решения о ретраях или фатальном завершении. Для больших сообщений включайте компрессию и лимитируйте максимальный размер фрейма.

---

## Дедлайн чтения сообщений WebSocket

```python
import asyncio, aiohttp
READ_DEADLINE = 20.0

async def recv_with_deadline(ws: aiohttp.ClientWebSocketResponse):
    while True:
        async with asyncio.timeout(READ_DEADLINE):
            msg = await ws.receive()
        if msg.type == aiohttp.WSMsgType.TEXT:
            process(msg.data)
        elif msg.type in (aiohttp.WSMsgType.CLOSED, aiohttp.WSMsgType.ERROR):
            raise ConnectionError('ws closed')
```

**Описание:** Даже с heartbeat поток может «замолчать». Дедлайн чтения отлавливает немые зависания: сбои сервера, проблемные прокси, поломку бэкенда, когда сокет остаётся открытым. Это удобная граница для автоматического переподключения.

Комбинируйте с «минимальной скоростью» и квотами на обработку — если потребитель не успевает, лучше признать отставание и перезапуститься с ресинком, чем копить хвосты бесконечно.

---

## Очередь исходящих сообщений и отправитель

```python
import asyncio, aiohttp

class WSSender:

    def __init__(self) -> None:
        self.outbox: asyncio.Queue[str] = asyncio.Queue(maxsize=100)

    async def sender(self, ws: aiohttp.ClientWebSocketResponse):
        while True:
            data = await self.outbox.get()
            try:
                await ws.send_str(data)
            finally:
                self.outbox.task_done()

    async def send(self, data: str) -> None:
        await self.outbox.put(data)
```

**Описание:** Очередь защищает продюсера от медленного или временно недоступного канала: данные не теряются, а давление ограничено `maxsize`. Это естественная точка для backpressure — `put()` заблокируется, сигнализируя вызывающему коду, что канал «узкий».

Добавляйте `join()` при остановке, чтобы дождаться отправки/сброса очереди. Для приоритетов используйте `PriorityQueue` или несколько очередей. Следите за сериализацией — крупные сообщения лучше дробить и подтверждать отправку батчами.
---

## Переподключение WebSocket с экспоненциальным backoff

```python
import asyncio, contextlib, aiohttp
RECONNECT_BASE = 0.5
RECONNECT_MAX = 30.0

async def run_ws(url: str):
    attempt = 0
    async with aiohttp.ClientSession() as s:
        while True:
            ws = None
            try:
                ws = await s.ws_connect(url, heartbeat=10.0)
                attempt = 0
                while True:
                    msg = await ws.receive()
                    if msg.type == aiohttp.WSMsgType.TEXT:
                        handle(msg.data)
                    elif msg.type in (aiohttp.WSMsgType.CLOSED, aiohttp.WSMsgType.ERROR):
                        raise ConnectionError
            except (aiohttp.ClientError, ConnectionError, asyncio.TimeoutError):
                attempt += 1
                delay = min(RECONNECT_BASE * 2 ** (attempt - 1), RECONNECT_MAX)
                await asyncio.sleep(delay)
            finally:
                if ws is not None:
                    with contextlib.suppress(Exception):
                        await ws.close()
```

**Описание:** Экспоненциальный backoff защищает сервер от бурстов переподключений и даёт сети стабилизироваться. Сброс `attempt` после успешного подключения предотвращает выпадание в длинные задержки.

Добавьте джиттер и максимальное число попыток/тотальный дедлайн, чтобы не крутиться вечно при фатальных ошибках (неверный токен, 4xx‑коды рукопожатия). Логируйте причины разрывов и итоговые интервалы — это ускоряет RCA.

---

## Структурная конкурентность: HTTP‑батч + WebSocket под общим дедлайном

```python
import asyncio, httpx, aiohttp

async def http_batch(urls: list[str]) -> None:
    async with httpx.AsyncClient() as c:
        await asyncio.gather(*(c.get(u) for u in urls))

async def ws_forever(url: str) -> None:
    async with aiohttp.ClientSession() as s:
        async with s.ws_connect(url, heartbeat=10.0) as ws:
            async for msg in ws:
                consume(msg.data)

async def main():
    async with asyncio.timeout(30.0):
        async with asyncio.TaskGroup() as tg:
            tg.create_task(http_batch([f'https://api.example.com/{i}' for i in range(100)]))
            tg.create_task(ws_forever('wss://stream.example.com/v1/events'))
asyncio.run(main())
```

**Описание:** `TaskGroup` создаёт совместную судьбу подзадач: если падает одна — остальные аккуратно отменяются. Внешний дедлайн ограничивает всю композицию, что особенно важно для worker‑джоб и HTTP‑ручек с фиксированными тайм‑квотами.

Под каждую подзадачу стоит вешать собственные ретраи/таймауты, а отмену трактовать как «нормальную завершённость по политике». При необходимости очищайте ресурсы в `aclose()/finally` и публикуйте итоговые метрики по каждой ветке (успех/отмена/ошибка) — так видно, где именно «горит».
---

## Итоговые рекомендации

* Фиксировать **фазовые таймауты** и общий **дедлайн**.
* Использовать **один клиент на компонент** для reuse соединений.
* Ограничивать конкуренцию через **Semaphore**.
* Добавлять **метрики** через event hooks.
* Для WebSocket — heartbeat, дедлайн чтения, очередь исходящих и **backoff‑переподключение**.
