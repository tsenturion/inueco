# Блокирующие операции и адаптеры в async‑программах
**ThreadPoolExecutor · ProcessPoolExecutor · CPU‑bound задачи в процессах · Интеграция sync API в async‑код**

> Практический конспект с готовыми паттернами. Помогает безопасно вызывать блокирующие функции внутри `asyncio`‑приложений, не «замораживая» event loop.

## Содержание
1. [Когда нужны адаптеры: threads vs processes](#когда-нужны-адаптеры-threads-vs-processes)
2. [ThreadPoolExecutor: I/O‑bound из async](#threadpoolexecutor-io-bound-из-async)
3. [ProcessPoolExecutor: CPU‑bound в процессы](#processpoolexecutor-cpu-bound-в-процессы)
4. [Интеграция sync API в async‑программы](#интеграция-sync-api-в-async-программы)
5. [Таймауты, отмена и завершение пулов](#таймауты-отмена-и-завершение-пулов)
6. [Ограничение параллелизма и backpressure](#ограничение-параллелизма-и-backpressure)
7. [Мини‑проект: всё вместе](#мини‑проект-всё-вместе)
8. [Чек‑лист](#чек-лист)

---

## Когда нужны адаптеры: threads vs processes

| Тип задачи | Где исполнять | Почему |
|---|---|---|
| **I/O‑bound (блокирующий ввод‑вывод)**: файловая система, сеть, БД‑клиенты без `await` | **Потоки** (`ThreadPoolExecutor`, `asyncio.to_thread`) | Пока поток ждёт I/O, GIL освобождён; event loop остаётся отзывчивым |
| **CPU‑bound**: сжатие/шифрование, парсинг, обработка изображений, вычисления | **Процессы** (`ProcessPoolExecutor`) | GIL мешает распараллеливать CPU в потоках; процессы дают реальный параллелизм |
| **Sync API без async-версии** | Потоки (чаще), иногда процессы | Легче «обернуть» синхронный вызов в поток без переписывания библиотеки |

**Правило:** если код активно грузит CPU — используйте процессы; если в основном ждёт I/O — используйте потоки.

---

## ThreadPoolExecutor: I/O‑bound из async

### Быстрый способ: `asyncio.to_thread`
```python
import asyncio
import time

def blocking_read(path: str) -> str:
    time.sleep(0.05)           # имитация блокировки
    return open(path, "r", encoding="utf-8").read()

async def read_file_async(path: str) -> str:
    # передаём функцию и аргументы — asyncio сам использует thread pool
    return await asyncio.to_thread(blocking_read, path)
```
Этот пример показывает правильную адаптацию блокирующего I/O под asyncio. Функция blocking_read делает обычное чтение файла (да ещё и с искусственной задержкой time.sleep), что в чистом виде «заморозит» event loop. Обёртка await asyncio.to_thread(...) отправляет этот вызов в thread pool, освобождая цикл событий: пока поток ждёт диска, ваш async-код продолжает выполнять другие корутины. Это идеальный приём для интеграции синхронных библиотек без await — минимум бойлерплейта и естественная семантика await.

Практически: внутри blocking_read лучше использовать with open(...) as f: — так файл закроется даже при исключении. Если вы поддерживаете Python < 3.9, эквивалент — loop.run_in_executor(None, blocking_read, path). Помните, что to_thread/потоки не прерываются по отмене мгновенно: отмена завершит await, когда фоновая функция доработает; поэтому вокруг вызова полезно ставить таймауты (asyncio.timeout(...) в 3.11+, либо asyncio.wait_for в 3.8–3.10). Для большого количества параллельных операций ограничивайте конкурентность семафором и, при необходимости, создавайте явный ThreadPoolExecutor с разумным max_workers.

### Явное управление пулом потоков
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

def fetch_sync(url: str) -> bytes:
    # пример: requests.get(...) или другой sync-клиент
    import urllib.request
    with urllib.request.urlopen(url, timeout=5) as r:
        return r.read()

async def fetch_many(urls: list[str]) -> list[bytes]:
    loop = asyncio.get_running_loop()
    with ThreadPoolExecutor(max_workers=8, thread_name_prefix="io") as pool:
        tasks = [loop.run_in_executor(pool, fetch_sync, u) for u in urls]
        return await asyncio.gather(*tasks)
```

Этот пример решает классическую проблему: синхронный сетевой клиент (здесь urllib.request) блокирует поток на время I/O и «замораживает» event loop. Мы оборачиваем такие вызовы через loop.run_in_executor(pool, fetch_sync, u), тем самым передавая работу в ThreadPoolExecutor. Пока потоки ждут сеть/DNS/SSL-рукопожатие, цикл событий продолжает обслуживать другие корутины. Контекст-менеджер у пула гарантирует корректное завершение воркеров (shutdown(wait=True)), а asyncio.gather конкурентно собирает ответы.

Практические нюансы. Размер пула выбирайте под реальную нагрузку и внешние лимиты (часто 4–32 потоков достаточно для I/O); излишний пул увеличит переключения контекста и может ударить по удалённому сервису. Помните, что «отмена» таких задач не мгновенная: cancel() завершит ожидание только после завершения блокирующего вызова в потоке. Поэтому вокруг батча полезно ставить дедлайны (локальные таймауты на запрос и общий на весь батч), ограничивать параллелизм семафором и продумывать ретраи с backoff. Для устойчивости явно обрабатывайте ошибки — либо через return_exceptions=True у gather, либо через try/except в обёртке, чтобы не потерять частично успешные результаты.

Ещё детали. Тип list[str] требует Python 3.9+; на 3.8 используйте from typing import List и аннотацию List[str]. Сетевые клиенты вроде requests работают по тем же правилам — их также выносите в потоки или переходите на нативный async-клиент (httpx/aiohttp), если это возможно. Следите за ресурсами: устанавливайте таймауты сокетов, проверяйте заголовки/размер ответа, при необходимости лимитируйте суммарный объём скачиваемых данных. И наконец, если такие вызовы — горячий путь сервиса, подумайте о переезде на полноценный async-стек (пул подключений, TLS-reuse), чтобы уменьшить накладные расходы потоков и повысить предсказуемость задержек.

**Советы**
- Давайте **разумный `max_workers`**: для I/O‑bound 4–32 потоков часто достаточно.
- Для простых случаев предпочитайте `asyncio.to_thread` — меньше бойлерплейта.
- Потоки не убивают процесс при падении — обязательно оборачивайте I/O в try/except.

---

## ProcessPoolExecutor: CPU‑bound в процессы

### Базовый шаблон
```python
import asyncio
from concurrent.futures import ProcessPoolExecutor

def cpu_heavy(n: int) -> int:
    # Функция на верхнем уровне модуля (picklable) — требование для процессов
    # Защищаемся от n == 0, чтобы не ловить ZeroDivisionError
    m = n or 1
    s = 0
    for i in range(1_000_000):
        s = (s + i) % m
    return s

async def compute_many(nums: list[int]) -> list[int]:
    loop = asyncio.get_running_loop()
    # Процессы дают реальный параллелизм для CPU-bound
    with ProcessPoolExecutor(max_workers=4) as pool:
        tasks = [loop.run_in_executor(pool, cpu_heavy, n) for n in nums]
        return await asyncio.gather(*tasks)

# На Windows/macOS запуск корутин с процессами — только под guard:
if __name__ == "__main__":
    asyncio.run(compute_many([1, 2, 0, 5]))
```
Этот пример правильно выносит CPU-тяжёлую работу в ProcessPoolExecutor, чтобы обойти GIL и получить реальный параллелизм по ядрам. Ключевые требования для процессов: передаваемые функции и данные должны быть picklable (поэтому cpu_heavy объявлена на верхнем уровне модуля), а на Windows/macOS запускать код с процессами нужно под защитой if __name__ == "__main__":. Внутри cpu_heavy добавлена защита от n == 0 (иначе будет ZeroDivisionError), а количество итераций записано явно (1_000_000) ради читаемости.

Корутинa compute_many планирует синхронные cpu_heavy(n) в процессный пул через loop.run_in_executor(pool, ...) и конкурентно собирает результаты await asyncio.gather(...). Помните, что отмена здесь не мгновенная: воркер-процесс доработает текущий кусок, прежде чем завершиться; если нужен жёсткий лимит, оберните ожидание в таймаут (asyncio.timeout(...) в 3.11+ либо asyncio.wait_for(...) на 3.8–3.10). Аннотация list[int] требует Python ≥ 3.9; на 3.8 используйте typing.List[int].



> **Windows/macOS:** защищайте точку входа `if __name__ == "__main__":` в скриптах, где создаётся `ProcessPoolExecutor`, иначе процессы‑дети не стартуют корректно.

### Когда процессный пул обязателен
- Хеширование/шифрование, сжатие, обработка изображений, машинное обучение без GIL‑release.
- Любая функция, у которой загрузка CPU ≥ ~80% времени.

---

## Интеграция sync API в async‑программы

### Вариант 1: быстрый адаптер вокруг sync‑клиента
```python
import asyncio, json, time
import requests  # sync‑клиент

def get_json_sync(url: str) -> dict:
    r = requests.get(url, timeout=5)
    r.raise_for_status()
    return r.json()

async def get_json(url: str) -> dict:
    # не блокируем event loop
    return await asyncio.to_thread(get_json_sync, url)
```
Этот фрагмент показывает правильную интеграцию синхронного HTTP-клиента (requests) в асинхронную программу: вместо прямого вызова, который «заморозит» event loop, синхронная функция get_json_sync отправляется в пул потоков через await asyncio.to_thread(...). Пока поток выполняет TCP/TLS-рукопожатие, ждёт ответ и парсит JSON, цикл событий остаётся отзывчивым и может выполнять другие корутины. Такой приём удобен, когда переписать зависимость на нативный async-клиент нельзя (наследие, сторонняя библиотека, корпоративные ограничения).

Важно понимать поведение отмены и таймаутов. Отмена get_json(...) кооперативна: await завершится, когда фоновый поток закончит работу, поэтому вокруг вызова полезно ставить внешний дедлайн (asyncio.timeout(...) в Python 3.11+ или asyncio.wait_for на 3.8–3.10), дополняя сокетный таймаут requests (вы уже используете timeout=5). Хорошая практика — различать «сокетный» и «общий» бюджеты времени (например, 3–4 с общий дедлайн поверх 5 с на сокете) и корректно логировать TimeoutError/RequestException, чтобы понимать, где именно «сгорело» время.

Про надёжность и производительность. Если вызовов много, подумайте о переиспользовании соединений через requests.Session() и о ретраях с экспоненциальным backoff + jitter (на 5xx, ConnectTimeout, ReadTimeout). Лимитируйте параллелизм семафором, чтобы не «заддосить» внешний сервис и не распухал пул потоков. При появлении нативной async-альтернативы (например, httpx.AsyncClient/aiohttp) переход на неё обычно даёт предсказуемее латентность, лучшее управление отменой и меньше накладных расходов на контекст-переключения потоков — но до тех пор asyncio.to_thread остаётся простым и безопасным адаптером.

### Вариант 2: адаптация цепочек вызовов и ретраев
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
import random

_pool = ThreadPoolExecutor(max_workers=4)

def blocking_call(x: int) -> int:
    if x % 3 == 0:
        raise RuntimeError("flaky")
    return x * 2

async def call_with_retries(x: int, retries: int = 3, base_delay: float = 0.05, deadline: float = 1.0) -> int:
    loop = asyncio.get_running_loop()
    async with asyncio.timeout(deadline):  # общий дедлайн на всё
        attempt = 0
        while True:
            try:
                return await loop.run_in_executor(_pool, blocking_call, x)
            except RuntimeError:
                attempt += 1
                if attempt >= retries:
                    raise
                # экспоненциальный backoff + джиттер
                delay = base_delay * (2 ** (attempt - 1))
                delay *= 1 + 0.2 * (random.random() - 0.5)
                await asyncio.sleep(delay)
```
Этот пример аккуратно адаптирует синхронную «чужую» функцию под асинхронный код и добавляет управляемые ретраи. Блокирующий вызов (blocking_call) исполняется в ThreadPoolExecutor через loop.run_in_executor(...), поэтому event loop не замирает. Пул создаётся один раз на весь цикл попыток (он объявлен вне for), что экономит накладные расходы на создание/уничтожение потоков. Между попытками используется await asyncio.sleep(...) — это не блокирует цикл и даёт другим корутинам продолжить работу.

Исключение RuntimeError трактуется как «временная» ошибка и перехватывается для повтора; на последней попытке оно корректно пробрасывается наружу. Важно, что вы не ловите asyncio.CancelledError: отмена остаётся «сквозной», и вышестоящий код может прервать операцию (правильное поведение для async-API). Помните, что задачи в thread pool не прерываются мгновенно: если поток завис в системном вызове, отмена завершится только после его возврата. Поэтому в проде полезно ставить общий дедлайн на весь вызов (в 3.11+ — asyncio.timeout, в 3.8–3.10 — asyncio.wait_for) и/или использовать сокетные таймауты внутри самой синхронной библиотеки.

Для повышения устойчивости подумайте об экспоненциальном backoff с джиттером, чтобы не стрелять повторами одновременно и не создавать пульсирующую нагрузку. Если таких вызовов много, имеет смысл держать один общий ThreadPoolExecutor на приложение (или использовать asyncio.to_thread в 3.9+), а ещё — ограничивать параллелизм семафором, чтобы не «раскрутить» слишком много потоков. Логи/метрики по количеству попыток и причинам ошибок помогут быстрее видеть деградации внешней зависимости и настраивать пороги ретраев/таймаутов под реальные p95/p99.



### Вариант 3: комбинируем процессы и потоки
- Предобработка/парсинг I/O‑тяжёлых файлов — в **потоках**.
- CPU‑интенсивные стадии пайплайна (например, ресайз/фильтры изображений) — в **процессах**.

---

## Таймауты, отмена и завершение пулов

### Таймауты
Используйте `asyncio.timeout()` вокруг `await`:
```python
import asyncio
from pathlib import Path

def _read_bytes(path: Path) -> bytes:
    with open(path, "rb") as f:
        return f.read()

async def guarded_fetch(path: str | Path) -> bytes:
    async with asyncio.timeout(0.5):            # общий дедлайн
        return await asyncio.to_thread(_read_bytes, Path(path))
```
Этот пример сочетает два правильных приёма: адаптацию блокирующего I/O в пул потоков и явный таймбокс операции. Вызов await asyncio.to_thread(...) переносит чтение файла (open(...).read()) в background-поток, поэтому event loop остаётся отзывчивым и может выполнять другие корутины. Снаружи шаг обёрнут в asyncio.timeout(0.5) (Python 3.11+), что превращает возможное зависание в детерминированный TimeoutError и документирует SLA операции: «чтение должно уложиться за 500 мс».

Стоит чуть улучшить безопасность: читать файл лучше внутри контекстного менеджера (with open(...) as f:), чтобы гарантированно закрывать дескриптор даже при исключениях, а саму функцию чтения вынести из лямбды в именованную def (проще тестировать и переиспользовать). Помните, что отмена таких операций не мгновенная — поток завершит текущий системный вызов, и только тогда await вернёт управление. Если нужен кросс-версийный вариант без asyncio.timeout, используйте await asyncio.wait_for(asyncio.to_thread(...), timeout=...). Для большого числа параллельных чтений ограничивайте конкурентность семафором, чтобы не открыть слишком много файлов одновременно.

### Отмена
- `asyncio.to_thread(...)` **нельзя прервать мгновенно**: отмена задачи дождётся завершения фонового потока и поднимет `CancelledError` вызывающему. Планируйте разумные таймауты.
- `run_in_executor(...)` ведёт себя схоже: задача в пуле дорабатывает; отмену отражайте в вашей логике повторов/таймаутов.

### Завершение пулов
- Используйте контекст‑менеджеры (`with ThreadPoolExecutor(...) as pool:`) — это гарантирует `shutdown(wait=True)`.
- Для долгоживущих приложений уместен **один общий пул** на процесс, а не создание/закрытие пула на каждый вызов.

---

## Ограничение параллелизма и backpressure

### Семафор на верхнем уровне
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

def blocking_op(i: int) -> int:
    import time
    time.sleep(0.05)
    return i * i

_pool = ThreadPoolExecutor(max_workers=16)  # общий пул на процесс

async def run_bounded(items: list[int], limit: int = 8) -> list[int]:
    loop = asyncio.get_running_loop()
    sem = asyncio.Semaphore(limit)

    async def one(i: int):
        async with sem:
            return await loop.run_in_executor(_pool, blocking_op, i)

    return await asyncio.gather(*(one(i) for i in items))
```
Этот пример правильно сочетает два механизма: вынос блокирующей работы в ThreadPoolExecutor и ограничение параллелизма через asyncio.Semaphore. Внутри one(i) мы сначала «берём» слот у семафора, затем отправляем blocking_op в пул потоков через run_in_executor. Пока потоки ждут time.sleep(0.05) (или выполняют реальный sync-I/O), event loop остаётся отзывчивым, а семафор не даёт создать больше одновременно выполняемых задач, чем нужно. Это защищает от «взрыва» конкуренции: даже если пул на 16 потоков, фактическая одновременность ограничена восьмью «билетами» семафора.

Практически полезно сделать семафор и пул долгоживущими (например, передавать Semaphore параметром или держать общий _pool) — так вы не платите за их создание каждый вызов. Помните, что отмена задач из пула не мгновенная: cancel() вернёт управление только после завершения блокирующей функции, поэтому на верхнем уровне разумно держать общий дедлайн (asyncio.timeout в 3.11+ или asyncio.wait_for на более старых версиях). Если поддерживаете Python 3.9+, аналогичная запись возможна через await asyncio.to_thread(blocking_op, i); на 3.8 замените аннотацию list[int] на typing.List[int].


### Очередь задач
```python
import asyncio
from asyncio import Queue
from concurrent.futures import ProcessPoolExecutor

def cpu_job(x: int) -> int:
    return x * x  # placeholder

async def pipeline(nums: list[int]) -> list[int]:
    loop = asyncio.get_running_loop()
    q, out = Queue(), []

    with ProcessPoolExecutor(max_workers=4) as pool:
        async def producer():
            for n in nums:
                await q.put(n)
            for _ in range(4):
                await q.put(None)  # сигналы остановки

        async def consumers():
            async def consume():
                while True:
                    n = await q.get()
                    try:
                        if n is None:
                            return
                        res = await loop.run_in_executor(pool, cpu_job, n)
                        out.append(res)
                    finally:
                        q.task_done()
            await asyncio.gather(*(consume() for _ in range(4)))

        await asyncio.gather(producer(), consumers())
        await q.join()
    return out
```
Этот конвейер правильно соединяет asyncio-уровень с CPU-параллелизмом через ProcessPoolExecutor. Продюсер кладёт числа в asyncio.Queue, затем отправляет ровно по одному «сентинелу» None на каждого из четырёх потребителей, чтобы те корректно завершились. Каждый консьюмер забирает элемент, выполняет cpu_job в процессном пуле (loop.run_in_executor(pool, ...)), добавляет результат в общий список и обязательно вызывает q.task_done() в finally. Благодаря этому await q.join() надёжно возвращается, а конвейер не «висит» при ошибках. Поскольку процессы обходят GIL, такой подход даёт реальный выигрыш на CPU-bound задачах.

Нюансы эксплуатации: порядок результатов в out не гарантирован (он определяется скоростью отдельных процессов) — если важна упорядоченность, передавайте и индекс (например, (idx, n)) и раскладывайте по месту после gather. На Windows/macOS (режим spawn) следите, чтобы модуль был import-safe и, если это самостоятельный скрипт, используйте if __name__ == "__main__": для запуска; все функции, вызываемые в процессах, должны быть picklable (определены на верхнем уровне). Отмена кооперативна и не прерывает уже выполняющуюся работу в воркере, поэтому для стабильности добавляйте внешний дедлайн (asyncio.timeout/wait_for) вокруг ожиданий и по необходимости ограничивайте объём очереди (maxsize), чтобы не переполнить память при больших партиях.
---

## Мини‑проект: всё вместе

```
project/
├─ src/adapters.py
├─ src/pipeline.py
├─ tests/test_pipeline.py
└─ pytest.ini
```

**`src/adapters.py`**
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor

# ---- I/O адаптер (threads)
def read_text_sync(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

async def read_text(path: str) -> str:
    return await asyncio.to_thread(read_text_sync, path)

# ---- CPU адаптер (processes)
def digest_sync(data: bytes) -> str:
    import hashlib
    return hashlib.sha256(data).hexdigest()

async def digest(data: bytes) -> str:
    loop = asyncio.get_running_loop()
    with ProcessPoolExecutor(max_workers=2) as pool:
        return await loop.run_in_executor(pool, digest_sync, data)
```
Этот пример аккуратно разделяет два типа блокирующей работы: I/O и CPU. Для чтения файла используется asyncio.to_thread, который отправляет синхронную функцию read_text_sync в thread pool и не блокирует event loop — корутины продолжают выполняться, пока поток читает с диска. Для вычислений применяется ProcessPoolExecutor: digest() выносит CPU-тяжёлую функцию digest_sync в отдельный процесс, обходя GIL и получая реальный параллелизм. Важно помнить о согласовании типов: read_text() возвращает str, а digest() ждёт bytes, значит перед вызовом стоит сделать text.encode("utf-8") (или внутри digest_sync принять str и выполнить .encode(...)).

Практика и нюансы: создание ProcessPoolExecutor на каждый вызов — затратная операция; при частых вычислениях держите пул «долго живущим» и переиспользуйте его. Потоки и процессы не прерываются мгновенно, поэтому вокруг ожиданий полезно ставить общий дедлайн (asyncio.timeout в 3.11+ или asyncio.wait_for на более ранних версиях) и логировать таймауты. Уберите неиспользуемый импорт ThreadPoolExecutor. Если запускаете код как скрипт на Windows/macOS (режим spawn), следите за guard if __name__ == "__main__": вокруг кода, который создаёт процессы. Такой шаблон — хороший «адаптер» для интеграции sync-библиотек и CPU-задач в asyncio-приложение без переписывания зависимостей.

**`src/pipeline.py`**
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from .adapters import digest

def load_sync(path: str) -> bytes:
    with open(path, "rb") as f:
        return f.read()

async def build_manifest(paths: list[str]) -> dict[str, str]:
    loop = asyncio.get_running_loop()
    sem = asyncio.Semaphore(8)
    with ThreadPoolExecutor(max_workers=16) as pool:
        async def one(p: str) -> tuple[str, str]:
            async with sem:
                data = await loop.run_in_executor(pool, load_sync, p)
            h = await digest(data)  # CPU‑bound в процессах
            return p, h
        pairs = await asyncio.gather(*[one(p) for p in paths])
        return dict(pairs)
```
Этот конвейер делит работу по назначению: блокирующее I/O (чтение файлов) уезжает в пул потоков, а CPU-тяжёлое хэширование делается в процессах внутри адаптера digest. Внутри build_manifest создаётся локальный семафор на 8 «билетов», чтобы не запускать больше параллельных чтений, чем позволяет файловая подсистема; сами чтения выполняются через loop.run_in_executor(pool, load_sync, p), поэтому event loop не блокируется. После чтения байты передаются в await digest(data), и уже там процессный пул обходит GIL. Результаты собираются через asyncio.gather и превращаются в словарь {path: hash} — порядок прихода не важен.

Практические нюансы. Относительный импорт from .adapters import digest сработает только внутри пакета; если модуль запускается напрямую, используйте абсолютный импорт пакета. Создавать ThreadPoolExecutor на каждый вызов — немного затратно: при частых запусках держите общий пул (или замените на компактное await asyncio.to_thread(load_sync, p), где пулом управляет asyncio). Отмена таких операций не мгновенная (поток/процесс доработает текущий шаг), поэтому полезно обрамлять весь батч верхним дедлайном (asyncio.timeout в 3.11+ или asyncio.wait_for), а при необходимости добавить и локальные таймауты на чтение и на вычисление хэша. Если набор путей велик, можно ограничить и CPU-конкурентность (например, семафором вокруг digest) — так вы контролируете пик нагрузки и память.

Надёжность и эксплуатация. Подумайте об обработке ошибок: завернуть gather с return_exceptions=True и разложить успешные/провальные элементы, чтобы не терять весь манифест из-за одной проблемы чтения/хэширования. Для детерминизма стоит нормализовать пути (абсолютные, без дубликатов) до запуска и, при желании, считать хэши потоково (чанками), чтобы не держать крупные файлы целиком в памяти. Если проект крутится на Windows/macOS и digest внутри действительно создаёт процессы, следите, чтобы модуль адаптера был import-safe и запуск основного скрипта проходил под if __name__ == "__main__":. В остальном структура уже удачная: I/O ограничено семафором, CPU вынесен в процессы, event loop остаётся отзывчивым.

**`tests/test_pipeline.py`**
```python
import asyncio, os, tempfile, pytest
from src.pipeline import build_manifest

@pytest.mark.asyncio
async def test_manifest():
    with tempfile.TemporaryDirectory() as d:
        paths = []
        for i in range(5):
            p = os.path.join(d, f"f{i}.txt")
            open(p, "wb").write(b"x" * (i + 1))
            paths.append(p)

        async with asyncio.timeout(2.0):
            m = await build_manifest(paths)

        assert set(m.keys()) == set(paths)
        assert all(len(v) == 64 for v in m.values())  # sha256
```
Этот тест проверяет весь конвейер «от диска до хэша» как чёрный ящик. Он создаёт временную директорию, записывает пять файлов разного размера и вызывает build_manifest(paths) в контексте asyncio.timeout(2.0). Такая обёртка превращает потенциальное зависание (например, из-за перегруженного диска или слишком большого параллелизма) в детерминированный TimeoutError, а проверка результата сводится к двум инвариантам: набор ключей равен исходным путям, а значения — 64-символьные строки (SHA-256). Использование TemporaryDirectory() гарантирует, что артефакты теста будут удалены автоматически, а @pytest.mark.asyncio корректно запускает корутину в event loop.

Стоит отметить, что внутри build_manifest смешиваются два вида адаптеров: I/O уезжает в пул потоков, а CPU-хэширование — в процессы. Поэтому на CI время может немного «гулять» в зависимости от нагрузки и числа ядер. Если тест становится чувствительным, можно снизить параллелизм в самой функции (лимиты семафоров/пулов) либо увеличить таймаут с запасом, опираясь на метрики. Для старых версий Python (<3.11) эквивалентом контексту asyncio.timeout будет await asyncio.wait_for(build_manifest(paths), timeout=2.0) — семантика ожидания сохранится.

Наконец, следите за кроссплатформенными нюансами: на Windows/macOS процессные пулы используют режим spawn, значит функции, выполняемые в процессах, должны быть определены на верхнем уровне модуля (picklable), а модуль с кодом — «import-safe». Если вы захотите дополнительно «закрутить гайки» к надёжности, можно добавить проверки содержимого манифеста (например, сравнить пару хэшей, посчитанных синхронно в тесте), а также лог/метрику времени шага — это поможет быстро ловить регрессии производительности без усложнения сценария.


**`pytest.ini`**
```ini
[pytest]
asyncio_mode = auto
```
Этот pytest.ini включает режим asyncio_mode = auto плагина pytest-asyncio. В этом режиме pytest сам создаёт и закрывает event loop для тестов с async def, поэтому декоратор @pytest.mark.asyncio становится необязательным: новые асинхронные тесты подхватываются автоматически. Это снижает бойлерплейт и вероятность «забыть маркер», из-за чего тест внезапно выполняется как обычная функция и падает странной ошибкой.

Важно расположить файл именно в том каталоге, откуда вы запускаете pytest (как правило — корень проекта). Альтернатива — задать опцию в pyproject.toml/tox.ini, но держать её в pytest.ini зачастую нагляднее. Следите, чтобы в проекте не было кастомных фикстур, которые вручную создают/закрывают event loop: с «auto» должен быть один источник правды управления циклом, иначе возможны конфликты и флаки.

Если понадобится более строгая изоляция, в свежих версиях можно перейти на asyncio_mode = strict — он строже отслеживает неправильное использование лупов и помогает вычищать артефакты. Отдельно помните про версию Python: сам режим «auto» работает везде, но конструкции вроде asyncio.timeout(...) требуют 3.11+; на 3.8–3.10 используйте эквивалент asyncio.wait_for(...). На CI полезно дополнить конфиг авто-фикстурой, которая после каждого теста отменяет и дожидается всех «висячих» задач — так вы сохраните чистый event loop между запусками.

---

## Чек‑лист

Определили тип задачи: I/O-bound → потоки; CPU-bound → процессы.
Потоки скрывают блокирующее ожидание диска/сети и не мешают event loop; для чистой математики/сжатия/хешей нужен ProcessPoolExecutor, т.к. GIL не даст ускорения в потоках. Если сомневаетесь — измерьте: I/O-профиль виден по времени системных вызовов, CPU-профиль — по загрузке ядра.

 Для простых адаптаций используете asyncio.to_thread.
Это самый короткий путь вынести синхронную функцию в thread pool без ручного менеджмента: await asyncio.to_thread(func, *args). Удобно для чтения/записи файлов, DNS, легковесных вычислений, когда переписывать библиотеку на async нельзя.

 CPU-тяжёлые функции вынесены в ProcessPoolExecutor, функции picklable и на верхнем уровне модуля.
Всё, что уходит в процессы (функции/аргументы/результаты), должно сериализоваться. Не вкладывайте функции и не используйте лямбды — определяйте def на верхнем уровне. На Windows/macOS запускайте код с guard’ом if __name__ == "__main__":.

 Таймауты стоят вокруг всех потенциально «залипающих» await.
Локальные лимиты на рискованные шаги (HTTP/БД/файлы) + общий дедлайн на сценарий. На Py 3.11+ — asyncio.timeout, на 3.8–3.10 — asyncio.wait_for. Помните: отмена кооперативная — закрывайте ресурсы в finally внутри операций.

 Пулы завершаются (with ... as pool), нет утечек фоновых workers.
Контекст-менеджер гарантирует shutdown(wait=True). Если пулы создаются часто — заведите один «долго живущий» инстанс и переиспользуйте. Следите, чтобы исключения из задач не «выплёскивались» после завершения теста/сценария.

 Ограничен параллелизм (Semaphore, Queue) — стабильный throughput без DDoS собственных ресурсов.
Даже если пул может 32 задачи, ставьте верхнюю границу конкурентности (I/O и, при необходимости, CPU). Для очередей соблюдайте баланс put → get → task_done() и ждите queue.join() — это надёжно завершает конвейер.

 Обработаны ошибки и ретраи.
Для «флейки» зависимостей внедрите ретраи с экспоненциальным backoff + jitter; отличайте таймауты от бизнес-ошибок. Решите политику: что логируем, что метрим, что пробрасываем наверх.

 Установлены реалистичные лимиты и учтены ресурсы.
Таймауты выбирайте по p95/p99 вашего окружения, не «с потолка». Следите за файловыми дескрипторами, портами, памятью — ограничение параллелизма помогает не «захлебнуться» при больших батчах.

 Отмена и детерминизм.
Помните, что потоки/процессы не прерываются мгновенно — обрамляйте ожидание дедлайном. На CI включайте PYTHONASYNCIODEBUG=1, фиксируйте seed RNG/время в тестах и держите автофикстуру, которая «подметает» висящие задачи после каждого кейса.

 Совместимость и структура кода.
Для Py < 3.9 заменяйте to_thread на run_in_executor; для Py < 3.11 — timeout на wait_for. Функции, уезжающие в процессы, — только верхнего уровня; модули — import-safe, особенно на Windows/macOS (spawn).
