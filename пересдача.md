# Асинхронные базы данных

> В этом конспекте — практическое введение в работу с БД в асинхронном Python: **драйверы** (на примере `asyncpg` и `redis.asyncio`/`aioredis`), **пулы соединений**, **транзакции** и **батчи**. Материал выстроен в том же стиле, что и остальные документы: короткие объяснения → аккуратные примеры кода → рекомендации и анти‑паттерны.

---

## О чём этот документ

* Зачем асинхронность для БД и чем она отличается от «параллелизма».
* Как выбирать и использовать асинхронные **драйверы**.
* Как работают **пулы соединений** и почему без них нельзя в проде.
* Как оформлять **транзакции** (в т.ч. с таймаутами и savepoint).
* Как делать **батчи**/пайплайны для повышения пропускной способности.
* Практические приёмы: ограничение параллелизма, ретраи, идемпотентность.

> Минимальные версии: Python 3.11+, PostgreSQL 12+, Redis 6+.

---

## 1. Асинхронные драйверы

Асинхронные драйверы не блокируют поток во время I/O: на `await` управление возвращается циклу событий, и другие корутины продолжают работу. Это особенно эффективно для БД‑запросов, которые чаще «ждут» сеть/диск, чем нагружают CPU.

### 1.1. Какие драйверы использовать

* **PostgreSQL** — `asyncpg` (минимальный оверхед, быстрый бинарный протокол).
* **Redis** — `redis.asyncio` (часть официального клиента `redis`), либо `aioredis` ≤2.x.
* Также существуют `motor` (MongoDB), `aioodbc`/`databases`, SQLAlchemy (async‑движки).

### 1.2. Базовые шаблоны использования
Этот пример показывает базовый жизненный цикл работы с asyncpg: установление соединения через asyncpg.connect(...), выполнение параметризованного запроса fetchrow(...) и аккуратное закрытие соединения в finally. Параметры запроса передаются позиционно ($1), что защищает от SQL-инъекций и обеспечивает корректное преобразование типов (например, int, uuid, datetime) на уровне драйвера. fetchrow возвращает одну строку (или None), а доступ к полям возможен по имени; в примере результат приводится к dict для наглядности. Обёртка asyncio.run(main()) создаёт и закрывает цикл событий, так что корутина main выполняется «с нуля» и без утечек ресурса.

С архитектурной точки зрения, код хорош как «hello world», но в приложениях под нагрузкой обычно переходят на пул соединений (asyncpg.create_pool) вместо открытия/закрытия коннекта на каждый запрос — это сильно снижает накладные расходы и стабилизирует latency. Ещё две практики для продакшена: (1) ставить таймаут на операции (например, asyncio.timeout(2.0) вокруг fetchrow), чтобы зависшие запросы не держали ресурсы бесконечно; (2) минимизировать время владения соединением — не выполнять долгие вычисления между connect() и close() или внутри блока acquire() (если используется пул). Наконец, старайтесь логировать SQL-исключения (PostgresError и производные) с контекстом запроса и параметров (без чувствительных данных), чтобы упростить разбор инцидентов.
1. **PostgreSQL: одиночное соединение и SELECT**

```python
import asyncio, asyncpg

async def main():
    conn = await asyncpg.connect('postgresql://user:pass@localhost:5432/app')
    try:
        user = await conn.fetchrow('SELECT id, email FROM users WHERE id=$1', 1)
        print(dict(user) if user else None)
    finally:
        await conn.close()
asyncio.run(main())```

2. **Redis: set/get c авто‑закрытием**

Во втором примере используется официальный клиент redis с асинхронным API (from redis.asyncio import Redis). Важная деталь — decode_responses=True: клиент автоматически декодирует байты в строки (UTF-8 по умолчанию), что удобнее при печати и сравнении значений в Python-коде. Паттерн тот же: создаём клиент, выполняем I/O-операции (await r.set(...), await r.get(...)), затем корректно закрываем соединения через await r.aclose(). Все вызовы — корутины, поэтому при ожидании ответа Redis текущая задача отдаёт управление event loop, и другие корутины могут одновременно делать свои запросы.

Для продакшена стоит учитывать несколько моментов. Во-первых, клиент уже использует пул соединений под капотом, но при интенсивной записи/чтении лучше группировать команды в pipeline (батчи) — это уменьшает количество round-trip и повышает пропускную способность. Во-вторых, продумайте семантику данных: если это кэш — добавляйте TTL (ex=...), если счётчики — используйте атомарные операции (INCR, HINCRBY), если требуется условная запись — SET ... NX/XX. В-третьих, добавляйте таймауты и ретраи для временных сетевых ошибок, а также избегайте смешивания синхронного клиента (старые примеры с redis.Redis() без asyncio) в асинхронном коде — синхронные вызовы будут блокировать цикл событий и «замораживать» всё приложение.

```python
import asyncio
from redis.asyncio import Redis

async def main():
    r = Redis(host='localhost', port=6379, decode_responses=True)
    try:
        await r.set('counter', 1)
        val = await r.get('counter')
        print(val)
    finally:
        await r.aclose()
asyncio.run(main())```

> Замечание: не смешиваем синхронные клиенты (например, `psycopg2`) с асинхронными — они будут блокировать event loop.

---

## 2. Пулы соединений

Создание/закрытие соединения с БД — дорогая операция. **Пул** держит открытый набор коннектов и раздаёт их конкурентным задачам. Это снижает latency и стабилизирует нагрузку.

### 2.1. Пул в `asyncpg`

3. **Создание пула и запрос с параметром**

В этом примере показан типовой жизненный цикл пула: create_pool(...) открывает набор соединений (от min_size до max_size) и возвращает объект-пул, который раздаёт коннекты конкурентным задачам. Контекст async with pool.acquire() as conn: берёт свободное соединение из пула и гарантирует его возврат даже при ошибках. Запрос параметризован ($1), что даёт безопасное подстановочное связывание и правильную сериализацию типов. Такой шаблон резко снижает накладные расходы на установку TCP/SSL-рукопожатий и аутентификацию по сравнению с открытием коннекта на каждый запрос.

Важно, что timeout=10.0 в create_pool — это пуловый таймаут (например, на инициализацию/получение коннекта), а не таймаут самого SQL-запроса. Для продовой надёжности обычно добавляют локальные таймауты вокруг конкретных операций (через asyncio.timeout(...)) и/или серверные лимиты (statement timeout на уровне БД). Ещё две практики: выносить любые не-SQL вычисления за пределы блока acquire() (минимизируя время «аренды» соединения) и логировать длительные удержания коннекта, чтобы выявлять узкие места (долгие транзакции, ожидание блокировок).

```python
import asyncio, asyncpg

async def main():
    pool = await asyncpg.create_pool('postgresql://user:pass@localhost:5432/app', min_size=1, max_size=10, timeout=10.0)
    try:
        async with pool.acquire() as conn:
            row = await conn.fetchrow('SELECT * FROM users WHERE id=$1', 42)
            print(dict(row) if row else None)
    finally:
        await pool.close()
asyncio.run(main())```

4. **Ограничение параллелизма поверх пула (semaphore)**

Второй фрагмент иллюстрирует «двойное дозирование» нагрузки: помимо предела по соединениям в пуле, мы добавляем семафор asyncio.Semaphore(limit), чтобы ограничить число одновременно выполняемых тяжёлых запросов. Это полезно, когда отдельный запрос может быть дорогим (сканы больших таблиц, сложные джоины) и наличие свободных коннектов ещё не означает, что сервер БД выдержит N параллельных тяжёлых планов. Обёртка async with sem: делает так, что одновременно в критическую секцию «доступ к БД» пройдёт не более limit задач.

Тонкость: limit не обязан равняться max_size пула — иногда его делают строже, чтобы избегать пиков и деградации (например, max_size=20, limit=8). Также обратите внимание, что gather(*(one(i) for i in ids)) запускает конкурентную фан-аут загрузку; если входной массив велик, разумно батчить ids порциями или применять «протекающее окно» (например, через asyncio.as_completed) — так вы сохраните стабильную нагрузку без всплесков памяти и очередей.

```python
import asyncio, asyncpg

async def bounded_fetch(pool, ids, limit=8):
    sem = asyncio.Semaphore(limit)

    async def one(uid):
        async with sem:
            async with pool.acquire() as conn:
                return await conn.fetchrow('SELECT * FROM users WHERE id=$1', uid)
    return await asyncio.gather(*(one(i) for i in ids))```

### 2.2. Рекомендации по настройке пула

Подбор max_size. Отталкивайтесь от max_connections (или пула сервера — pgbouncer) и профиля запросов. Часто выгоднее меньше, но стабильнее: например, 4–8 коннектов на инстанс веб-воркера вместо агрессивных 50+. Следите за временем ожидания коннекта и временем выполнения запросов — это две разные метрики, и обе должны быть в бюджете SLA.

Минимизируйте время владения соединением. Держите коннект только на «чистое I/O»: подготовили данные → acquire → await запрос → сразу освободили. Долгие вычисления, сериализация, JSON-манглинг — строго до или после использования коннекта. Это повышает RPS без роста max_size.

Таймауты на всём пути. Ставьте: (1) таймаут на получение коннекта (защита от «голодания»), (2) таймаут на конкретный SQL (защита от подвисаний/блокировок), (3) общий таймаут операции (SLA). Логируйте все срабатывания, чтобы видеть, где именно «горит».

Инициализация/валидаторы. Для пула полезны хуки инициализации (настройка search_path, локали, временных параметров), пинг-проверки (SELECT 1) и, при необходимости, «ре-сеттер» состояния после ошибки (сбрасывать транзакцию, временные таблицы).

Семантика конкуренции. Пул не заменяет backpressure. Для дорогих операций ограничивайте параллелизм семафором/очередью; если запросы короткие — чаще хватает одного пула. Следите, чтобы суммарные лимиты (пул + семафор) не приводили к дедлокам на уровне вашего приложения (например, когда одна корутина ждёт коннект, удерживая при этом другой лимит).

Наблюдаемость. Метрики: время ожидания acquire, длительность запросов, доля таймаутов/ошибок, глубина очередей задач, использование соединений (idle/active). Трассируйте запросы (корреляционные ID, span’ы), чтобы быстро находить «долгие» план-шаги.

---

## 3. Транзакции

Транзакция — атомарная группа операций: либо все, либо ни одной. В `asyncpg` это контекстный менеджер `conn.transaction()`; ошибки внутри блока приводят к `ROLLBACK`.

### 3.1. Базовая транзакция (двойное обновление)

5. **Перевод денег с блокировкой строки**

Этот код демонстрирует классический шаблон «денежного перевода» в одной транзакции: вначале берём соединение из пула, затем открываем conn.transaction(), чтобы обеспечить атомарность. Ключевой момент — SELECT ... FOR UPDATE: он захватывает блокировку строки кошелька-источника до конца транзакции, исключая гонки при параллельных переводах. Проверка бизнес-правила (bal < amount) выполняется внутри транзакции, так что состояние, на основе которого принимается решение, согласовано с последующими UPDATE.

С точки зрения надёжности, такой шаблон корректно откатывается при любой ошибке внутри блока — драйвер выполнит ROLLBACK. В проде стоит: (1) добавить таймаут на всю транзакцию и/или на отдельные запросы, чтобы не висеть на блокировках; (2) убедиться, что индексы поддерживают план SELECT ... FOR UPDATE по полю id; (3) учитывать изоляцию транзакций (обычно READ COMMITTED достаточно, но при сложных инвариантах может потребоваться SERIALIZABLE + ретраи).

```python
import asyncio, asyncpg

async def transfer(pool, from_id, to_id, amount):
    async with pool.acquire() as conn:
        async with conn.transaction():
            bal = await conn.fetchval('SELECT balance FROM wallet WHERE id=$1 FOR UPDATE', from_id)
            if bal < amount:
                raise ValueError('insufficient funds')
            await conn.execute('UPDATE wallet SET balance=balance-$1 WHERE id=$2', amount, from_id)
            await conn.execute('UPDATE wallet SET balance=balance+$1 WHERE id=$2', amount, to_id)```

### 3.2. Таймауты и корректная отмена

6. **Таймаут шага внутри транзакции**

Здесь транзакция оборачивает вставку события в дополнительный «локальный» таймаут asyncio.timeout(2.0). Если вставка зависнет (сетевой глитч, блокировки, подвисший сервер), asyncio вызовет отмену корутины и выбросит TimeoutError. Благодаря контексту conn.transaction() отмена приведёт к откату всей текущей транзакции, то есть частичных эффектов не останется. В except место для логирования или маппинга на доменную ошибку (например, «SLA нарушен, повторите позже»).

Тонкость — кооперативная отмена: таймаут сработает, когда управление вернётся в event loop. Это нормально для I/O-операций драйвера, которые регулярно await-ят сокет. В реальном сервисе полезно различать: сбой шага внутри транзакции (может быть безопасно повторён) и общий отказ сервиса БД (стоит переключать маршрутизацию, троттлить поток, срабатывать circuit breaker’ом).

```python
import asyncio

async def with_step_timeout(conn):
    async with conn.transaction():
        try:
            async with asyncio.timeout(2.0):
                await conn.execute('INSERT INTO events(data) VALUES($1)', {'k': 'v'})
        except asyncio.TimeoutError:
            raise```

7. **Глобальный таймаут на операцию + аккуратное закрытие**

Второй фрагмент иллюстрирует «обёртку SLA» над всей операцией: сначала задаётся общий бюджет времени asyncio.timeout(5.0), и только затем берётся соединение из пула и выполняется запрос. Такой порядок важен: если долго ждём свободное соединение (пул исчерпан), всё равно сработает общий таймаут — вызывающий код не будет «висеть». Возвращаемое значение — результат SELECT now(), а в случае таймаута поднимется TimeoutError, который стоит логировать и превращать в корректный ответ API.

Практически полезно различать три уровня таймаутов: (1) на acquire (ожидание коннекта), (2) на конкретный SQL (ожидание ответа сервера/снятие блокировок), (3) на всю операцию (включая сериализацию/подготовку данных). Такое разделение упрощает диагностику — вы сразу видите, «узкое место» в пуле, на стороне БД или в вашем коде вокруг.

```python
async def safe_op(pool):
    async with asyncio.timeout(5.0):
        async with pool.acquire() as conn:
            return await conn.fetch('SELECT now()')```

### 3.3. Savepoint (частичный откат)

8. **Частичная откатка внутри транзакции**

Код показывает, как использовать SAVEPOINT, чтобы откатить часть транзакции, не отменяя весь блок. Сначала создаётся SAVEPOINT sp1, затем выполняется серия вставок. Если возникает исключение (например, конфликт уникальности), мы откатываемся к сейвпоинту, а затем повторяем вставки уже в «безопасном» режиме через INSERT ... ON CONFLICT DO UPDATE — по сути, переключаемся на upsert-стратегию, сохраняя уже успешные изменения до сейвпоинта.

Этот приём полезен, когда в батче могут встретиться «грязные» записи, а полная отмена всего набора нежелательна. Однако важно следить за временем жизни транзакции: множественные попытки и проходы по данным внутри одного transaction() увеличивают длительность удержания блокировок и нагрузку на журнал. Практики для проде: лимитировать размер батча, логировать количество конфликтов/повторов, по возможности валидировать/нормализовать данные до БД, а также рассмотреть выполнение upsert сразу (без первой «чистой» попытки), если конфликты — норма для вашего потока данных.

```python
async def upsert_batch(conn, rows):
    async with conn.transaction():
        await conn.execute('SAVEPOINT sp1')
        try:
            for r in rows:
                await conn.execute('INSERT INTO items(id,val) VALUES($1,$2)', r[0], r[1])
        except Exception:
            await conn.execute('ROLLBACK TO SAVEPOINT sp1')
            for r in rows:
                await conn.execute('INSERT INTO items(id,val) VALUES($1,$2)\nON CONFLICT (id) DO UPDATE SET val=excluded.val', r[0], r[1])```

> Практика: ставьте разумные таймауты на транзакции (SLA) и на отдельные запросы, логируйте отмены и длительные блокировки.

---

## 4. Батчи (Batch) и пайплайны

Батчи уменьшают количество сетевых round‑trip и/или объединяют множество однотипных операций в одну транзакцию. Это критично для массовых вставок, апдейтов и загрузки справочников.

### 4.1. PostgreSQL: `executemany` и copy‑протокол

9. **Массовая вставка через `executemany`**

Этот фрагмент показывает классический приём: одна транзакция оборачивает серию однотипных вставок через conn.executemany(...). Главное преимущество — сокращение сетевых round-trip’ов: клиент не делает отдельный begin/commit на каждую запись и не тратит время на повторную подготовку запроса. Для типичных батчей (десятки–сотни строк) executemany даёт ощутимый выигрыш без дополнительной сложности, а параметризованная форма ($1, $2) остаётся безопасной к инъекциям и корректно сериализует типы.

На практике стоит внимательно подбирать размер батча: слишком маленькие порции увеличивают накладные расходы, слишком большие — растят время удержания блокировок и риск конфликтов/таймаутов. Хорошая стратегия — динамический размер (например, 500–5 000 строк) с метриками длительности шага и количеством конфликтов. Ещё два совета: добавляйте таймаут на транзакцию/запрос, а при возможных дубликатах сразу используйте upsert (INSERT ... ON CONFLICT DO NOTHING/UPDATE) — это сократит повторные проходы и упрощает обработку ошибок.

```python
async def insert_many(pool, data):
    async with pool.acquire() as conn:
        async with conn.transaction():
            await conn.executemany('INSERT INTO events(id, name) VALUES($1, $2)', data)```

10. **Быстрая загрузка через `copy_records_to_table`**

copy_records_to_table использует серверный протокол COPY, который существенно ускоряет bulk-вставки за счёт потоковой передачи данных на стороне сервера. Это золотой стандарт для «тяжёлых» загрузок (тысячи–миллионы строк): меньше оверхеда на парсинг отдельных INSERT и меньше round-trip’ов. Код лаконичен: указываем целевую таблицу, список колонок и передаём итератор/список записей — драйвер сам оформит протокол.

Есть нюансы. Во-первых, COPY эффективен, но предъявляет требования к валидации: ошибка в одной записи может прервать всю операцию — иногда выгоднее грузить порциями и вести лог проблемных строк. Во-вторых, длинная COPY-сессия удерживает ресурсы и может конфликтовать с DDL/долгими транзакциями; планируйте размер порций и ставьте таймауты. В-третьих, не забывайте про индексы и триггеры: массовая вставка в сильно индексированную таблицу может «просесть» — иногда ускоряет временное отключение вторичных индексов/триггеров с последующим восстановлением (если это допустимо процессом).

```python
async def bulk_copy(pool, rows):
    async with pool.acquire() as conn:
        await conn.copy_records_to_table('events', records=rows, columns=['id', 'name'])```

### 4.2. Redis: pipeline/transaction

11. **Пакетная запись ключей (pipeline)**

Пайплайн с transaction=True буферизует команды и отправляет их одним «пакетом», уменьшая число сетевых поездок и повышая пропускную способность. В примере мы последовательно вызываем p.set(...) в цикле, а затем await p.execute() — все команды выполнятся на сервере, и клиент получит собранные ответы. Для сценариев «много мелких SET/GET» это может дать кратный прирост производительности, особенно через сеть с заметной латентностью.

Практически полезно контролировать максимальный размер пайплайна (например, 100–1 000 команд) и мерить время исполнения, чтобы не создавать гигантские пакеты, задерживающие флаш и увеличивающие хвостовые задержки. Если вам не нужна атомарность всего пакета, можно оставить transaction=False — сервер выполнит команды по порядку без оборачивания в MULTI/EXEC (чуть меньше нагрузки). Для кэш-сценариев добавляйте TTL на уровне команд (SET key value EX …), а для массовых счётчиков используйте атомарные операции (INCRBY, HINCRBY) — это дешевле и надёжнее, чем «прочитал-увеличил-записал».

```python
from redis.asyncio import Redis

async def write_batch(r: Redis, n: int=100):
    async with r.pipeline(transaction=True) as p:
        for i in range(n):
            p.set(f'k:{i}', i)
        return await p.execute()```

12. **READ‑MODIFY‑WRITE с `WATCH` (оптимистичная блокировка)**

Этот пример реализует классический оптимистичный CAS-шаблон: WATCH key фиксирует версию ключа, далее читаем значение, вычисляем новое, объявляем MULTI (p.multi()), ставим SET и пытаемся EXEC через await p.execute(). Если ключ менялся конкурентно, транзакция отменится, код поймает исключение и повторит попытку. Такой подход обеспечивает корректность при гонках без глобальных блокировок на сервере и хорошо подходит для редких конфликтов.

Что стоит учесть на практике: добавьте ограничение числа повторов и экспоненциальную паузу (backoff), чтобы не «крутиться» бесконечно под высокой конкуренцией. Если конфликты часты или требуется строгая атомарность сложной логики, рассмотрите Lua-скрипт (EVAL) — он выполняется целиком на сервере атомарно и исключает окно между GET и SET. И наконец, помните про истечения ключей/TTL и сериализацию типов: int(v or 0) в примере безопасно обрабатывает отсутствие значения, но для сложных структур лучше использовать H*-команды или кодировать JSON/MsgPack с проверкой схемы.

```python
async def incr_atomic(r: Redis, key: str):
    while True:
        async with r.pipeline() as p:
            await p.watch(key)
            v = await r.get(key)
            v = int(v or 0) + 1
            p.multi()
            p.set(key, v)
            try:
                await p.execute()
                return v
            except Exception:
                continue```

---

## 5. Параллелизм запросов и backpressure

13. **Fan‑out/Fan‑in с ограничением**

Этот хелпер принимает список корутин coros и ограничивает их одновременное выполнение семафором asyncio.Semaphore(limit). Внутренняя обёртка wrapped(coro) захватывает «пропуск» у семафора — так в критической секции одновременно окажется не больше limit задач — и только затем делает await coro. В конце asyncio.gather(...) выполняет «fan-in»: собирает результаты всех конкурентно запущенных задач и возвращает их в исходном порядке.

Зачем это нужно, если у нас уже есть пул соединений к БД? Пул ограничивает ресурс соединений, но не гарантирует, что сама работа (тяжёлые запросы) не перегрузит сервер. Семафор — второй уровень дозирования, который даёт тонкий контроль над пиковыми нагрузками (например, limit=20, даже если в пуле 50 коннектов). Ещё нюанс: gather поднимет первое исключение и отменит оставшиеся задачи. Если нужно обрабатывать частичные ошибки, используйте return_exceptions=True и разберите результаты, либо идите через asyncio.as_completed(...) — он позволяет обрабатывать готовые результаты по мере поступления, удерживая «скользящее окно» параллелизма.

```python
import asyncio

async def run_limited(coros, limit=20):
    sem = asyncio.Semaphore(limit)

    async def wrapped(coro):
        async with sem:
            return await coro
    return await asyncio.gather(*(wrapped(c) for c in coros))```

14. **Очередь задач для БД**

Шаблон с asyncio.Queue строит pipeline «производитель → очередь → несколько воркеров». Производители складывают пары (sql, args) в очередь, а воркеры (worker) бесконечно извлекают задания (await q.get()), выполняют их в контексте async with pool.acquire() и в любом случае вызывают q.task_done() — так поддерживается корректный учёт завершённых задач. start_workers поднимает n фоновых воркеров и возвращает очередь; через неё вы дозируете нагрузку на БД, а количество воркеров определяет ширину параллелизма.

Ключевая деталь — Queue(maxsize=100): ограниченная очередь формирует backpressure. Если потребители (БД/воркеры) не успевают, очередь заполняется, и попытка q.put() у производителей будет ждать — это естественная обратная связь, не дающая «взорвать» память и не создающая лавины конкурирующих транзакций. Пара советов: (1) добавляйте таймауты на acquire и на сам execute, чтобы не зависать на блокировках; (2) логируйте глубину очереди и длительность обработки — это ранние индикаторы перегруза; (3) держите внутри acquire только чистый I/O (никаких долгих CPU-частей), чтобы коннекты быстро возвращались в пул. Если задания неоднородны по «весу», подумайте о нескольких пулах/очередях (например, «быстрые» и «тяжёлые»), чтобы тяжёлые не вытесняли лёгкие.

```python
from asyncio import Queue, create_task

async def worker(name, pool, q: Queue):
    while True:
        sql, args = await q.get()
        try:
            async with pool.acquire() as conn:
                await conn.execute(sql, *args)
        finally:
            q.task_done()

async def start_workers(pool, n=4):
    q = Queue(maxsize=100)
    for i in range(n):
        create_task(worker(f'w{i}', pool, q))
    return q```

> Ограниченная очередь и семафоры — естественный механизм **backpressure**: если потребители (БД) не успевают, производители вынуждены ждать.

---

## 6. Ретраи, идемпотентность и ошибки

15. **Ретрай с jitter для временных ошибок**

Функция retry(coro_factory, attempts=3, base=0.2) реализует повтор вызова корутины с экспоненциальной паузой: при каждой неуспешной попытке ожидание растёт как base * 2**i, а random.random() * 0.1 добавляет небольшой jitter. Джиттер важен в распределённых системах: если множество клиентов одновременно увидят сбой (например, краткий «флап» БД) и перезапустят запросы с одинаковым интервалом, они будут синхронно «долбить» сервер. Случайная компонента рассинхронизирует пики и снижает вероятность «штормов» повторов.

Что ещё помнить: (1) ретраи оправданы только для временных ошибок (сетевые таймауты, перегрузка, transient-конфликты блокировок). Для логических ошибок (уникальные ограничения, валидация) повтор не поможет и только усугубит ситуацию; фильтруйте исключения, которые стоит повторять. (2) Операции должны быть идемпотентны или иметь защиту от двойной записи: для БД — INSERT ... ON CONFLICT ..., для внешних эффектов — уникальные request_id и логи дубликатов. (3) Добавьте общий верхний лимит времени/попыток и телеметрию: метрика «число ретраев, средняя задержка, доля успехов после ретраев» отличная для раннего обнаружения деградаций.

```python
import asyncio, random

async def retry(coro_factory, attempts=3, base=0.2):
    for i in range(attempts):
        try:
            return await coro_factory()
        except Exception as e:
            if i == attempts - 1:
                raise
            await asyncio.sleep(base * 2 ** i + random.random() * 0.1)```

16. **Идемпотентные операции**

* В PostgreSQL — `INSERT ... ON CONFLICT DO UPDATE`.
* В Redis — храните версию/хэш, проверяйте перед записью.
* На уровне приложения — присваивайте запросам уникальные `request_id` и логируйте уже обработанные.

---

## 7. Анти‑паттерны

* Долго держать соединение «в руках», выполняя не относящиеся к БД вычисления.
* Открывать/закрывать соединения на каждый запрос вместо пула.
* Отсутствие таймаутов и контроля отмены → зависшие задачи и утечки коннектов.
* «Всё параллелить» без семафоров/очередей → пики, блокировки, timeouts на стороне БД.
* Смешивать синхронные драйверы с асинхронным фреймворком.

---

## 8. Мини‑чеклист

* [ ] Используем асинхронный драйвер БД.
* [ ] Все вызовы — через пул.
* [ ] На каждый запрос/транзакцию — таймаут.
* [ ] Конкуренцию дозируем семафором/очередью.
* [ ] Массовые операции — батчами/пайплайнами/копированием.
* [ ] Идемпотентность и ретраи для временных сбоев.
