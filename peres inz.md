# Тестирование асинхронного кода в Python
**pytest-asyncio · IsolatedAsyncioTestCase · Моки и патчи для async-функций · Контроль и поиск «висячих» задач**

> Готовый конспект с примерами, чтобы быстро поставить на рельсы тестирование `async`-кода.

## Содержание
1. [pytest-asyncio: быстрый старт](#pytest-asyncio-быстрый-старт)
2. [unittest: IsolatedAsyncioTestCase](#unittest-isolatedasynciotestcase)
3. [Моки и патчи для async-функций](#моки-и-патчи-для-async-функций)
4. [Контроль и поиск «висячих» задач](#контроль-и-поиск-висячих-задач)
5. [Мини-проект: всё вместе](#мини-проект-всё-вместе)
6. [Чек-лист для PR и CI](#чек-лист-для-pr-и-ci)

---

## pytest-asyncio: быстрый старт

### Включение
**Вариант A — маркер на тесте**
```python
# tests/test_service.py
import asyncio
import pytest

async def fetch_user(uid: int) -> dict:
    await asyncio.sleep(0.01)
    return {"id": uid, "name": "Ada"}

@pytest.mark.asyncio
async def test_fetch_user_ok():
    data = await fetch_user(1)
    assert data["name"] == "Ada"
```
pytest-asyncio разворачивает корректную модель исполнения для async def-тестов, чтобы ваш event loop не мешал остальным тестам и не «тянулся» между кейсами. Когда вы включаете asyncio_mode = auto, плагин сам решает, когда создавать и закрывать цикл, а также корректно проклеивает все await внутри теста. Это избавляет от случайных «подвисаний» и флаки, которые часто появляются, если смешивать синхронные фикстуры, реальные сетевые вызовы и фоновые задачи без явной изоляции. Важно помнить, что таймауты — это не только страховка от зависаний, но и документирование намерений: локальные timeout вокруг «узких мест» (доступ к кэшу, обращение к БД, шаг сериализации) делают точки деградации предсказуемыми и легко диагностируемыми. Ещё один частый источник проблем — долгоживущие синглтоны (HTTP-клиенты, коннекторы к брокеру), которые скрыто держат соединения между тестами: закрывайте их в фикстурах уровня function/module, чтобы цикл и ресурсы завершались вместе с тестом.

Практически в каждом проекте полезно вводить простые правила: любой тест, где возможна блокирующая операция, должен либо мокаться на границе (HTTP/БД/файловая система), либо иметь явный таймаут. Любые фоновые задачи, созданные внутри теста или тестируемого кода, должны быть именованы (create_task(..., name="...")) и завершены/отменены до конца теста; удобный паттерн — автоподключаемая фикстура, которая после yield собирает «висяки» через asyncio.all_tasks() и отменяет их с ожиданием завершения. Это гарантирует, что состояние цикла и планировщика остаётся чистым, а результаты тестов — детерминированными. Если вы запускаете много async-тестов параллельно (через -n в pytest-xdist), следите за тем, чтобы сетевые порты, временные файлы и переменные окружения не пересекалис

**Вариант B — глобально через pytest.ini**
```ini
# pytest.ini
[pytest]
# Современный режим: декоратор @pytest.mark.asyncio НЕ обязателен
asyncio_mode = auto

# Если хотите жёсткую изоляцию (pytest-asyncio ≥ 0.21):
# asyncio_mode = strict
```

### Таймауты, чтобы тесты не висели
```python
# tests/test_timeouts.py
import asyncio
import pytest

@pytest.mark.asyncio
async def test_step_has_timeout():
    async with asyncio.timeout(0.05):
        await asyncio.sleep(0.1)  # упадёт по таймауту
```
> Внутри «долгоиграющей» корутины будет `CancelledError`, снаружи — `asyncio.TimeoutError`. Закрывайте сетевые соединения/ресурсы в `finally`.
Режим asyncio_mode = auto избавляет от необходимости расставлять @pytest.mark.asyncio и даёт предсказуемый жизненный цикл event loop для каждого теста. Это особенно удобно в смешанных наборах, где есть и async, и обычные синхронные тесты: плагин сам создаёт и закрывает цикл там, где нужно, не влияя на соседние кейсы и фикстуры. Если у вас есть долгоживущие ресурсы (HTTP-сессии, пул соединений БД), держите их в фикстурах и закрывайте там же — «авто-режим» не должен оставаться заложником одинокого глобального клиента, открытого в модуле.

Иногда «auto» не подходит — например, когда вы специально управляете циклом сами (собственный loop_factory, интеграция с нестандартным рантаймом/реактором). В таких случаях оставляйте явные маркеры @pytest.mark.asyncio на конкретных тестах или заведите отдельный pytest.ini для этого набора. Из практики: если включили auto, убедитесь, что в кодовой базе не осталось кастомных фикстур, которые сами создают/закрывают loop — это может конфликтовать и приводить к флаки.

### Пара советов
Не допускайте реального I/O в юнит-тестах: стабильно мокайте границы (HTTP/БД/файлы). Реальную сеть оставляйте интеграционным тестам.

Для очередей держите баланс put/get/task_done() и дожидайтесь queue.join() — иначе тест «повиснет» навсегда.

Делайте авто-уборку фоновых задач через автOUSE-фикстуру: после yield соберите asyncio.all_tasks(), отмените и дождитесь их через gather(..., return_exceptions=True).

Не используйте time.sleep(...) в async-тестах. Если нужно уступить управление — await asyncio.sleep(0).

Фиксируйте тайминги и случайность: задавайте seed для RNG и используйте «заморозку» времени/таймеров в тестах, чтобы исключить флаки.

Включайте отладку asyncio на CI (PYTHONASYNCIODEBUG=1 или loop.set_debug(True)) — это помогает ловить забытые await и долгие колбэки.

Таймауты — не только «сетка»: ограничивайте и CPU-шаги (парсинг/сериализация), чтобы явно видеть деградации.

Не «shield’ьте» всё подряд: asyncio.shield разумно применять точечно, иначе отмена не дойдёт до задач и они останутся висеть.

Для конкурентных этапов используйте TaskGroup (3.11+): падение одной подзадачи автоматически отменит соседей и не оставит «хвостов».

Логи — часть проверок: через caplog/capfd можно утверждать, что отмена/таймаут действительно произошли (и не было неожиданных warnings).

## unittest: IsolatedAsyncioTestCase
Если вы на стандартном `unittest`, используйте изоляцию цикла и привычные ассерт-методы.

```python
# tests/test_api_unittest.py
import asyncio
from unittest import IsolatedAsyncioTestCase

class TestAPI(IsolatedAsyncioTestCase):
    async def test_basic(self):
        async def work():
            await asyncio.sleep(0.01)
            return 42
        self.assertEqual(await work(), 42)

    async def test_with_timeout(self):
        with self.assertRaises(asyncio.TimeoutError):
            async with asyncio.timeout(0.01):
                await asyncio.sleep(0.1)
```
Почему это удобно. IsolatedAsyncioTestCase создаёт отдельный event loop на каждый тестовый метод и сам управляет его жизненным циклом. Это означает, что фоновые задачи, таймауты и отмены из одного теста не «протекут» в другой. Плюс остаётся привычный для больших кодовых баз интерфейс unittest: assert*, иерархия базовых классов, setUp/tearDown. Для асинхронных ресурсов пользуйся именно asyncSetUp/asyncTearDown: так HTTP-сессии, подключения к БД, клиенты брокеров и т.д. открываются/закрываются корректно в асинхронном контексте, без «переупаковки» в синхронные обёртки.

На что обратить внимание. Любые созданные внутри теста фоновые задачи нужно явно завершать или отменять; изоляция цикла не освобождает от аккуратной уборки. Ошибки из задач могут всплывать после выхода из теста, поэтому полезно держать автопроверку на «висяки» (сбор all_tasks() и gather(..., return_exceptions=True) в asyncTearDown). Таймауты в unittest оформляй через контекст asyncio.timeout(...) + assertRaises(asyncio.TimeoutError) — так явнее видно SLA шага. Если смешиваешь unittest и pytest в одном проекте, договорись о единообразии: либо оставляй классы там, где важна наследуемая логика сетапов, либо постепенно мигрируй на pytest-фикстуры, но не перемешивай стили в пределах одного модуля.

Практические рекомендации:

Используй AsyncMock/patch из unittest.mock для асинхронных функций и контекст-менеджеров; проверяй вызовы через assert_awaited*, а не assert_called*.

Все «границы» (HTTP/БД/файлы/очереди) стабильно мокай; реальный I/O — только в интеграционных тестах.

Для детерминизма фиксируй случайность (seed) и время (freeze-time), особенно если есть ретраи/backoff.

Включай отладку asyncio на CI (PYTHONASYNCIODEBUG=1 или loop.set_debug(True)), чтобы ловить забытые await и долгие колбэки.

Если запускаешь тесты параллельно (xdist/много процессов), следи, чтобы порты, временные файлы и переменные окружения не конфликтовали между воркерами.

Не держи глобальные синглтоны с долгоживущими соединениями между тестами; открывай/закрывай их в asyncSetUp/asyncTearDown.

Для конкурентных сценариев внутри тестируемого кода предпочитай TaskGroup (3.11+): падение одной подзадачи автоматически отменит остальных и не оставит «хвостов».

Логи — часть проверок: через захват логов можно утверждать, что таймаут/отмена действительно произошли и не было неожиданных предупреждений.


Когда выбирать:
- Большая кодовая база уже на `unittest`.
- Нужны классические `assert*` и знакомые хуки setUp/tearDown.

---

## Моки и патчи для async-функций

### Подмена метода класса на `AsyncMock`
```python
# tests/test_service_mock.py
import asyncio
import pytest
from unittest.mock import AsyncMock, patch


class Client:
    """Пример синхронного клиента, эмулирующего I/O без реальной сети."""
    async def get_user(self, uid: int) -> dict:
        # имитация I/O (БД/HTTP): в реальном коде здесь был бы вызов к внешнему сервису
        await asyncio.sleep(0.001)
        return {"id": uid, "name": f"User{uid}"}


async def load_user(client: Client, uid: int) -> str:
    """Бизнес-логика: получить юзера и вернуть его имя."""
    data = await client.get_user(uid)
    return data["name"]


# --- Тесты ---

@pytest.mark.asyncio
async def test_load_user_happy_real_impl():
    """Проверяем работу без моков — на простой «реальной» реализации."""
    name = await load_user(Client(), 7)
    assert name == "User7"


@pytest.mark.asyncio
async def test_load_user_with_mock():
    """Проверяем изоляцию: подменяем внешний вызов моком и утверждаем поведение."""
    fake = AsyncMock(return_value={"id": 42, "name": "Linus"})
    with patch.object(Client, "get_user", fake):
        name = await load_user(Client(), 42)
        assert name == "Linus"
        fake.assert_awaited_once_with(42)

Зачем и как это работает. AsyncMock — специальный мок для async def, который корректно «ожидается» (await), хранит историю вызовов и умеет проверять, что его действительно ждали. В примере мы патчим метод Client.get_user на экземпляр AsyncMock: тест больше не ходит во внешний мир, а возвращает заранее известный словарь. Благодаря этому load_user получает стабильный вход, и мы проверяем только логику преобразования данных, а не сетевую часть.

Что именно проверять. Минимальный набор — это утверждение результата (вернулось имя) и факт вызова мока с ожидаемыми параметрами. Для асинхронных моков используйте проверки семейства assert_awaited* (а не assert_called*): так вы ловите случаи, когда функцию забыли «дождаться», и она вернула корутину вместо результата. Полезно также проверять количество ожиданий (assert_awaited_once), порядок (через assert_has_awaits), и сбрасывать состояние между проверками (reset_mock) — это делает тесты более точными и уменьшает ложноположительные срабатывания.

Возвраты и ошибки. AsyncMock(return_value=...) задаёт «успешный» путь; side_effect позволяет эмулировать исключения, задержки, чередование ответов. Это удобно, чтобы убедиться, что код правильно обрабатывает таймауты, ретраи и падения зависимостей. Если интерфейс метода сложнее (например, он возвращает объект с методом json()), мокируй и вложенные вызовы — главное, чтобы поведение на уровне публичного контракта выглядело правдоподобно.

Спеки и безопасность. Чтобы ловить опечатки в именах методов и неправильные сигнатуры, добавляй spec/spec_set (или патчи patch.object(..., spec=True)): тогда мок не позволит вызвать несуществующий атрибут и предупредит о неверных параметрах. Это особенно полезно в крупных проектах, где интерфейсы часто эволюционируют.

Модуль пути и область патча. Патчить нужно там, где объект используется, а не где он объявлен. Если load_user импортирует Client из модуля service, патчи ставятся на service.Client.get_user. Иначе тест «не попадёт» в реальный вызов, и вы получите ложное ощущение контроля. Держите патч в контексте (with patch.object(...)) или фикстуре — по выходу из контекста среда гарантированно возвращается к исходному состоянию.

Частые кейсы вокруг async.
— Асинхронный контекст-менеджер: у мока должны быть __aenter__/__aexit__, тоже асинхронные.
— Асинхронный итератор: реализуйте __aiter__, который отдаёт значения через async for.
— Смешение MagicMock/Mock c AsyncMock: не подменяйте async def обычным Mock — вы поймаете «корутину вместо результата».
— Неблокирующая изоляция: мокируйте границы (HTTP/БД/файлы) всегда, а реальные вызовы переносите в интеграционные тесты.

Что делает тест по шагам. Сначала создаётся «фейковая» асинхронная зависимость: AsyncMock будет вести себя как async def-функция и при await вернёт заранее заданный словарь. Далее контекст patch.object(...) подменяет реальный метод Client.get_user на этот мок — только в пределах with, чтобы по выходу окружение вернулось к исходному. Мы вызываем тестируемую функцию load_user, которая внутри делает await client.get_user(uid), и проверяем бизнес-результат: имя извлекается из полученных данных. Это важный сигнал: тест изолирован от сети/БД, гоняет чистую логику и даёт детерминированный, быстрый прогон.

Почему проверяем именно assert_awaited_once_with(7). Обычные проверки семейства assert_called* не ловят распространённую ошибку: забыли await, и код возвратил корутину вместо результата. В асинхронном случае корректно проверять, что зависимость была действительно ожидана — assert_awaited*. Одновременно фиксируем и параметры (UID) — это защищает от скрытых дефектов, когда функция вызывается с неверными аргументами (например, перепутали порядок, тип или забыли преобразование). Если логика допускает несколько обращений к зависимостям, используйте assert_has_awaits/assert_awaited и, при необходимости, reset_mock() между шагами — так вы получите точные и читаемые проверки без «перетаскивания» состояния между ассерциями.

Вариации и подводные камни. Если нужно эмулировать ошибку внешнего сервиса — задайте side_effect и проверьте, что код правильно обрабатывает исключение (логирует, ретраит, пробрасывает дальше). Для защиты от опечаток и изменения интерфейса добавляйте spec/spec_set, чтобы мок не принимал несуществующие атрибуты и неправильные сигнатуры. Патчить следует в месте использования (модуль, где импортирован Client), иначе вы «подмените не то» и проверка пройдёт мимо реального вызова. И не смешивайте Mock/MagicMock с async-API: обычный мок вернёт корутину и тест ложно «пройдёт», пока в проде код упадёт — AsyncMock решает именно эту проблему.

# tests/test_aiohttp_mock.py
from types import SimpleNamespace
from unittest.mock import AsyncMock
import pytest

@pytest.mark.asyncio
async def test_aiohttp_like_context_manager():
    # Ответ, у которого есть async-метод json()
    response = SimpleNamespace(
        json=AsyncMock(return_value={"ok": True})
    )

    # Контекстный менеджер с async __aenter__/__aexit__
    cm = SimpleNamespace(
        __aenter__=AsyncMock(return_value=response),
        __aexit__=AsyncMock(return_value=None),
    )

    # "Сессия": get(...) возвращает объект, поддерживающий async with
    # (в реальном aiohttp это request context manager)
    session = SimpleNamespace(get=AsyncMock(return_value=cm))

    # Код, как в проде: async with session.get(url) as resp: ...
    async with session.get("http://example") as resp:
        data = await resp.json()

    # Проверки результата и того, что протокол был пройден корректно
    assert data["ok"] is True

    # get(...) здесь НЕ await-ится (он возвращает контекст-менеджер),
    # поэтому проверяем обычный вызов, а не "awaited"
    session.get.assert_called_once_with("http://example")

    # А вот __aenter__/__aexit__ и resp.json() — именно awaited
    cm.__aenter__.assert_awaited_once()
    cm.__aexit__.assert_awaited_once()
    response.json.assert_awaited_once()

 Что именно мы эмулируем. В реальном aiohttp вызов session.get(url) возвращает объект-контекстный менеджер: конструкция async with session.get(url) as resp: под капотом вызывает await cm.__aenter__() и в конце await cm.__aexit__(...). Внутри блока вы работаете с «ответом» (resp), у которого, как правило, есть асинхронные методы (.json(), .text(), .read(), итерация по чанкам и т. п.). Наш тест воссоздаёт этот протокол: get() возвращает контекстный менеджер (а не готовый ответ), у контекстного менеджера реализованы асинхронные __aenter__/__aexit__, а «ответ» имеет асинхронный метод .json().

Почему проверяем именно такие вызовы. Важный акцент: session.get(...) — это обычный вызов, он не await-ится (возвращает объект-КМ), поэтому его корректно проверять через «был вызван», а не «был ожидаем». А вот __aenter__, __aexit__ и метод json — именно «ожидаемые» (await), значит, для них важно утверждать факт ожидания: это ловит ошибки, когда код забыли «дождаться» и случайно сместили порядок операций. Такая проверка защищает от коварных багов, при которых тест «проходит» (потому что мок возвращает что-то правдоподобное), а в проде код падает (потому что реальный объект требовал await).

Детерминизм и изоляция. Конструкция с AsyncMock на каждом «асинхронном» узле (вход/выход из контекста, метод получения тела) делает тест детерминированным: никакой реальной сети, никаких таймаутов и флаки. Вы тестируете только то, как ваш код обрабатывает ответ, а не TCP/HTTP. Благодаря явному разделению ролей (session → context manager → response) вы также получаете чёткие точки утверждений: был ли вызван get с верным URL, действительно ли произошёл вход/выход из контекста, был ли прочитан payload.

Реалистичность интерфейса. Чтобы мок выглядел как «настоящий» ответ, полезно имитировать основные атрибуты: status, headers, альтернативные методы (text, read, «стриминг» чанками). Это помогает раннее ловить несовпадения контрактов: если прод-код начнёт обращаться к resp.status или к resp.iter_chunked, а в тесте этого нет, вы сразу увидите падение и исправите мок/код. При необходимости включайте «жёсткую» спецификацию (аналог spec/spec_set), чтобы любые опечатки и несуществующие атрибуты проявлялись как ошибки, а не молча проглатывались.

Отдельно про ошибки и задержки. Полезно прогнать несколько веток: успех (возвращаем корректный JSON), ошибка соединения (исключение в __aenter__), ошибка парсинга (исключение в json), «задержка» на чтении тела (чтобы проверить таймауты/ретраи). Такие сценарии показывают, что ваш код корректно освобождает ресурсы (выходит из контекста даже при исключении), правильно логирует, делает повторные попытки или пробрасывает ошибку наверх. Это повышает уверенность, что в бою код поведёт себя предсказуемо.

Почему важны счётчики ожиданий. Утверждения «сколько раз ожидали» (на __aenter__, json) помогают обнаружить лишние/повторные чтения ответа или, наоборот, их отсутствие. Например, если логика должна прочитать тело ровно один раз, а тест показывает два ожидания — это сигнал о дублирующей обработке, утечках или неявных повторных вызовах. Аналогично с выходом из контекста: гарантируйте, что __aexit__ действительно «случился», иначе соединение/ресурсы могут остаться открытыми.

Где патчить и как не промахнуться. Всегда подменяйте объект там, где он используется. Если тестируемая функция импортирует session из своего модуля, то патч ставится на этот модуль, а не на место первоначального объявления. Иначе подмена «не поймает» реальный вызов и тест даст ложное чувство контроля. Это общая привычка для всех патчей: целиться в точку использования.

Про читаемость и сопровождение. Имена на моки/контекст-менеджеры/ответы серьёзно упрощают отладку: в отчётах вы сразу видите, кто был вызван и в каком порядке. Не поленитесь писать краткие комментарии «что за слой» (session → CM → response) — следующий человек (и вы через месяц) быстрее поймёт структуру и причину падения. Также избегайте переиспользования одного и того же мока между тестами: сбрасывайте состояние или создавайте свежие экземпляры — это исключает «протечки» счётчиков вызовов и неожиданные зависимости между кейсами.

Сочетаемость с таймаутами и фикстурами. Даже при полной эмуляции сети имеет смысл сохранять привычку «обрамлять» чувствительные шаги таймаутами — это документирует SLA и ловит регрессии по времени. А автOUSE-фикстура, которая «подметает» висящие задачи после теста, гарантирует чистоту event loop и избавляет от редких полтергейстов, когда ошибка проявляется «в следующем тесте».   

### Проверка таймаута через подмену «медленной» функции
# tests/test_timeout_patch.py
import asyncio
import types
import pytest
from unittest.mock import AsyncMock, patch

# ----- "внешняя" зависимость, которую будем патчить -----
# эмулируем модуль api с функцией get_user
api = types.SimpleNamespace()

async def _real_get_user(uid: int) -> dict:
    # быстрая реализация по умолчанию
    await asyncio.sleep(0.001)
    return {"id": uid}

api.get_user = _real_get_user


# ----- код под тестом: использует api.get_user с таймаутом -----
async def fetch_with_timeout(uid: int) -> dict:
    async with asyncio.timeout(0.05):           # важен Python 3.11+
        return await api.get_user(uid)


# ----- тест: подменяем get_user на "медленную" версию и ловим TimeoutError -----
@pytest.mark.asyncio
async def test_timeout_on_slow_call():
    async def slow(_uid: int):
        await asyncio.sleep(1.0)  # заведомо дольше лимита

    # Патчим ТАМ, ГДЕ ИСПОЛЬЗУЕТСЯ: <этот_модуль>.api.get_user
    with patch(__name__ + ".api.get_user", AsyncMock(side_effect=slow)):
        with pytest.raises(asyncio.TimeoutError):
            await fetch_with_timeout(42)
Идея теста и что мы доказываем. Мы искусственно превращаем зависимость (api.get_user) в «медленную» корутину и ожидаем, что наша обёртка с таймаутом среагирует корректно — бросит asyncio.TimeoutError. Такой тест не про сеть как таковую; он про контракт времени: если шаг занимает дольше бюджета, сценарий не должен висеть, он должен детерминированно» падать по таймауту. Это важнее, чем просто «успешный путёвый кейс»: по времени чаще всего и ломается прод — из-за деградаций или внешних зависимостей.

Почему патч «в месте использования». Патчим api.get_user не там, где он объявлен, а там, где его импортирует и вызывает тестируемый код. Это золотое правило patch: целиться нужно в объект, на который смотрит текущий модуль во время исполнения. Если ошибиться с путём и подменить «не ту» копию функции, вызов пройдёт мимо мока, тест станет зелёным «по случайности», а в реальном сценарии таймаут не сработает. В нашем варианте мы гарантированно перехватываем ссылку, которой пользуется fetch_with_timeout.

Почему AsyncMock с side_effect=slow. Нам нужно, чтобы зависимость вела себя как настоящая async def — её можно было await-ить, и она реально ждала внутри. AsyncMock обеспечивает корректную семантику await и счётчики ожиданий, а side_effect=slow делает поведение реалистичным: функция действительно «задерживается», а не просто возвращает «спящий объект». Это важно, потому что именно вложённый await и триггерит кооперативную отмену при срабатывании таймаута.

Как работает отмена и что вы реально тестируете. Внутри asyncio.timeout при превышении лимита в выполняемую корутину вбрасывается CancelledError. Это исключение «всплывает» в ближайшей точке ожидания (у нас — внутри «медленной» функции), после чего контекст снаружи преобразует его в TimeoutError. Поэтому ресурсы нужно закрывать внутри «медленной» части в блоке finally: отмена кооперативная и может прийти в любой await. Тест проверяет именно этот контракт: «если шаг не уложился в X мс — сценарий завершится по времени и очистит состояние».

Альтернатива для старых Python. На версиях < 3.11 нет контекста asyncio.timeout. Эквивалент — await asyncio.wait_for(coro, timeout=...). Семантика схожая (вложенный CancelledError → наружный TimeoutError), но читаемость хуже и вкладывать сложнее. Если проект живёт на 3.10 и ниже, уместно держать небольшой «полиморфный» хелпер (например, with timeout(t): ...) и реализовать его через wait_for.

Граничащие сценарии, которые тоже стоит покрыть.

Пограничное время: «успех на 90% таймаута» и «провал на 110%». Это выявляет хрупкие места и чувствительность к джиттеру планировщика.

Повторные попытки: одна «медленная» попытка + быстрая следующая. Проверяем, что ретраи не обходят таймауты и не «проглатывают» отмену.

Исключение вместо задержки: side_effect бросает RuntimeError. Убеждаемся, что наш слой не путает «ошибку зависимости» и «таймаут», и логирует по-разному.

Глобальный дедлайн + локальные лимиты: вложить локальный timeout на вызов зависимости в общий таймбокс сценария. В отчёте видно, где «сломалось» — в локальном шаге или вышли за бюджет всего теста.

Очистка ресурсов: даже при TimeoutError должны закрыться клиенты/сессии/семафоры. Это лучше проверять захватом логов/метрик или счётчиками вызовов на «close/exit».

Надёжность и детерминизм. Чтобы тест не флакал, ограничивайте конкуренцию: не гоняйте параллельно десятки тайм-критичных тестов на том же ядре, задайте seed RNG и по возможности избегайте реальной сети/диска. На CI включайте PYTHONASYNCIODEBUG=1 — он помогает подсветить «забытые await» и слишком долгие колбэки. Если используете пулы потоков/процессов в тестируемом пути, следите, что отмена не оставляет «зомби»-работников (в pytest можно повесить автOUSE-фикстуру на отмену/сбор «висящих» задач после yield).

Про конкретику ассертов. Минимум — «ожидаем TimeoutError». Лучше — дополнительно проверять поведение вокруг: записался ли лог о таймауте, не делалась ли повторная запись в кэш после отмены, не дёргалась ли зависимость повторно. С AsyncMock легко утверждать счётчики (assert_awaited_once_with(...), assert_has_awaits([...])). Это защищает от «тихих» регрессий, когда код вдруг стал вызывать зависимость дважды или стал забывать await.

Контракт и документация ожиданий по времени. Сам тест — это живая документация SLA: «вызов должен завершаться за ≤ 50 мс или падать». В описании теста/комментариях зафиксируйте, откуда взялась цифра (например, p95/порог деградации), и что должно происходить при выходе за неё (логирование, метрика, ретрай/фейл). Тогда изменение бюджета времени будет осознанным и видимым в код-ревью, а не «магическим» числом.

Итог. Такой паттерн (медленный мок + явный таймаут) обязывает код быть устойчивым к деградациям, подчёркивает границы ответственности (наш слой контролирует время, зависимость — нет) и делает падения объяснимыми. Когда тест краснеет — вы видите ровно тот шаг, который не уложился, а не расследуете «почему всё зависло где-то в недрах».

## Контроль и поиск «висячих» задач

# process_batch.py
import asyncio

async def worker(x: int) -> int:
    # имитация работы
    await asyncio.sleep(0.01)
    return x * 2

async def process_batch(items):
    results = []
    async with asyncio.TaskGroup() as tg:
        tasks = {tg.create_task(worker(it)): it for it in items}
    # к этому месту все задачи успешно завершены или отменены при ошибке
    # если хотите результаты — собирайте их внутри worker или через отдельный gather
    # здесь покажем простой повторный запуск для сбора результатов:
    return [await worker(it) for it in items]

 TaskGroup (Python 3.11+) — это «структурная конкуррентность» для asyncio: вы явно объявляете область, внутри которой живут связанные подзадачи, и цикл гарантирует, что вы покинете контекст только после их завершения. Ключевая польза — атомарность: если одна задача в группе падает, остальные автоматически отменяются, а наружу выбрасывается ExceptionGroup, из которой можно выборочно обработать типы ошибок через except*. Это резко снижает риск «висячих» фоновых задач и делает логику предсказуемой: либо успешно завершается весь набор работ, либо весь набор сворачивается при первой неисправимой ошибке.

Практически: внутри async with asyncio.TaskGroup() as tg: создавайте подзадачи через tg.create_task(...), по возможности давая имена — так трейс и логи читаются легче. Результаты удобно собирать двумя способами: (а) складывать их прямо внутри воркеров и возвращать агрегат после выхода из контекста, либо (б) сохранять ссылки на созданные задачи в список и читать task.result() уже после выхода — к этому моменту все они завершены (или отменены). Таймауты хорошо работают «матрёшкой»: локальные лимиты на отдельные шаги плюс общий дедлайн на всю группу — так вы видите, где именно произошло превышение бюджета. Не забывайте, что отмена кооперативная: освобождение ресурсов (сессий, файлов) делайте в finally внутри подзадач.

Совместимость и подводные камни: на Python ≤ 3.10 используйте asyncio.gather как ближайший аналог, но помните, что он не отменяет автоматически соседние задачи при падении одной (если не передан return_exceptions=True, исключение «порвёт» ожидание и оставит хвосты). Поэтому, если вы на 3.10, явно отменяйте оставшиеся задачи и дожидайтесь их gather(..., return_exceptions=True) в «уборочной» ветке. В любом случае, цель одна: чтобы после сценария не оставалось живых задач в планировщике и чтобы сбои были агрегированы и прозрачно видны тестам и мониторингу.   

### 2) Жёсткие таймауты на шаги и на сценарий

# tests/test_timeboxed_pipeline.py
import asyncio
import pytest

# "Сетевой" шаг: должен уложиться в 50 мс
async def maybe_slow_io():
    await asyncio.sleep(0.01)

# Остальная часть конвейера
async def rest_of_pipeline():
    await asyncio.sleep(0.02)

@pytest.mark.asyncio
async def test_pipeline_finishes():
    try:
        async with asyncio.timeout(0.2):       # общий дедлайн
            async with asyncio.timeout(0.05):  # «сетевой» шаг
                await maybe_slow_io()
            await rest_of_pipeline()
    except asyncio.TimeoutError:
        pytest.fail("pipeline exceeded time budget")

Жёсткие таймауты фиксируют SLA каждого шага и всего сценария: «локальный» лимит вокруг рискованной операции (сеть, RPC, запрос к БД) и «глобальный» дедлайн на весь пайплайн. Вложенная схема даёт ясную диагностику: если падает внутренний контекст — значит деградировал конкретный шаг; если срабатывает внешний — сценарий в целом превышает бюджет. Это превращает «подвисания» в детерминированные падения тестов и защищает от скрытых регрессий производительности. При этом отмена в asyncio кооперативная: TimeoutError снаружи означает, что внутри на ближайшем await был брошен CancelledError. Поэтому ресурсы (HTTP-сессии, файлы, курсоры) нужно закрывать в finally внутри шагов, а не надеяться на внешние «подмётки».

Практика: фиксируйте таймауты реалистично, опираясь на метрики (p95/p99) и добавляя небольшой запас, чтобы не получить флаки от планировщика и CI-нагрузки. Локальные лимиты ставьте на все «узкие места», даже если сейчас они быстрые: это документация ожиданий и ранний сигнал деградации. Глобальный дедлайн держите больше суммы шагов и учтите ретраи/backoff — иначе «правильные» повторы сами станут причиной фейла по времени. На Python < 3.11 используйте asyncio.wait_for как эквивалент; семантика та же, но вкладывать контексты чуть менее наглядна. Дополнительно полезно в тестах утверждать логи/метрики таймаутов (через caplog/счётчики): так вы проверяете не только падение, но и правильную реакцию системы на превышение бюджета.

### 3) Очереди: `queue.join()` и корректная остановка
# tests/test_queue_drains.py
import asyncio
import pytest
from asyncio import Queue

async def handle(item: int) -> None:
    # имитация обработки элемента очереди
    await asyncio.sleep(0.001)

async def _consumer(q: Queue):
    while True:
        item = await q.get()
        try:
            await handle(item)
        finally:
            q.task_done()

@pytest.mark.asyncio
async def test_queue_drains():
    q = Queue()
    consumer = asyncio.create_task(_consumer(q), name="bg:consumer")

    for i in range(3):
        await q.put(i)

    # дожидаемся обработки всех элементов
    await q.join()

    # аккуратно останавливаем фонового потребителя
    consumer.cancel()
    with pytest.raises(asyncio.CancelledError):
        await consumer
Зачем вообще queue.join(). В asyncio.Queue счётчик «необработанных» элементов увеличивается при каждом put() и уменьшается только вызовом task_done(). Пока счётчик > 0, await q.join() не вернёт управление. Это даёт простой и надёжный способ дождаться, что все элементы реально прошли через обработчик. Если забыть task_done() в finally, счётчик никогда не обнулится — тест будет висеть, хотя обработка фактически закончилась. Поэтому баланс put ↔ (get → task_done) — железное правило для любых очередей.

Отмена потребителя и «чистое» завершение. Потребитель — бесконечная корутина, и ей нужен «аккуратный выход». В тестах самый простой путь — consumer.cancel() после q.join(): мы гарантируем, что все элементы уже обработаны, и мягко гасим фон. Важно дождаться отменённой задачи (await consumer) и утвердить CancelledError, чтобы исключение не всплыло позже как «недождались отмены». Альтернатива — слать «сентинелы» (например, None) вместо отмены: каждый потребитель, получив маркер, выходит из цикла сам; это чуть многословнее, зато без исключений и подходит для прод-кода.

Backpressure и предсказуемость нагрузки. У очереди есть maxsize: если поставить разумный лимит и сначала вызвать await q.put(...), продюсер будет ожидать, когда потребители разгребут накопившееся. Это предотвращает всплески памяти и делает сценарий стабильнее под нагрузкой. В тестах это полезно для выявления «ускорителей», которые добавляют элементы быстрее, чем их успевают обрабатывать, — с лимитом вы быстро увидите, где именно образуется затор. Плюс это отличный способ сделать тайминги предсказуемыми: без неограниченной гонки между продюсером и потребителем.

Обработка ошибок в потребителях. Исключения внутри обработчика нельзя игнорировать: если handle(item) упадёт до task_done(), join() зависнет. Поэтому всегда оборачивайте обработку в try/finally: task_done() должен вызываться всегда, даже при ошибке. Дальше решайте политику: ретрай, DLQ (вторичная очередь для «битых» элементов), логирование, метрика — главное, чтобы тест явно проверял желаемое поведение: «ошибка не ломает дренаж очереди и не оставляет незавершённых задач».

Мульти-консьюмер и таймауты. Для нескольких потребителей join() по-прежнему корректно ждёт, пока каждый элемент будет «закрыт» task_done(). Но завершать таких потребителей лучше через столько же сентинелов, сколько у вас консьюмеров, — чтобы каждый получил сигнал к выходу. В тестах добавляйте «страховку времени» через asyncio.timeout(...) вокруг join(): это превращает висячий дефект в понятный TimeoutError и показывает место деградации. И наконец, помните про порядок: сначала await q.join() (гарантия, что очередь пуста), потом — останов потребителей и ожидание их завершения; так вы не теряете элементы на полпути и оставляете event loop в чистом состоянии.


### 4) Авто-уборка «висячих» задач фикстурой `pytest`
# conftest.py
import asyncio
import pytest

@pytest.fixture(autouse=True)
async def _cancel_pending_tasks():
    yield  # тест выполняется здесь

    cur = asyncio.current_task()  # задача этой фикстуры
    pending = [t for t in asyncio.all_tasks()
               if t is not cur and not t.done()]

    for t in pending:
        t.cancel()

    if pending:
        try:
            # ждём корректного завершения отменённых задач,
            # но не бесконечно (защита от некооперативного кода)
            await asyncio.wait_for(
                asyncio.gather(*pending, return_exceptions=True),
                timeout=0.5
            )
        except asyncio.TimeoutError:
            # по желанию: лог/предупреждение, чтобы заметить «упрямые» задачи
            pass
Зачем нужна такая фикстура. Даже аккуратный async-код иногда оставляет фоновые задачи: периодические пулы, «висящие» ретраи, незакрытые слушатели. Без авто-уборки эти задачи легко «перетекают» в следующий тест и вызывают флаки: непредсказуемые таймауты, занятые порты, повторные обращения к БД/HTTP. Авто-фикстура, включённая autouse=True, после каждого теста гарантированно просматривает текущий event loop, находит все живые задачи (кроме самой фикстуры), отменяет их и обязательно дожидается завершения — так цикл остаётся чистым, а тесты становятся детерминированными.

Как это работает концептуально. asyncio.all_tasks() возвращает набор задач текущего цикла; мы фильтруем уже завершённые и текущую, всем остальным кидаем cancel(). Отмена в asyncio кооперативная: исключение CancelledError поднимается в ближайшей точке await, поэтому важно не только отменить, но и дождаться, чтобы завершились finally-блоки и корректно освободились ресурсы (сессии, файлы, соединения). Именно для этого используется gather(..., return_exceptions=True): мы агрегируем исходы отмены, не роняя саму фикстуру, и не позволяем исключениям «выплеснуться» в следующую фазу.

Практические нюансы. Добавьте небольшой внешний таймаут на ожидание уборки (через wait_for) — это защищает от «упрямых» задач, которые игнорируют отмену и крутятся в CPU-цикле. Полезно включать лог/метрику, если уборка превысила бюджет времени: так вы заметите «тяжёлые» хвосты. И помните: фикстура не заменяет дисциплину — внутри тестов всё равно именуйте фоновые задачи, ставьте локальные таймауты на рискованные шаги, и в самом тестируемом коде корректно обрабатывайте CancelledError в finally. Тогда фикстура станет последней линией обороны, а не единственным средством наведения порядка.


## Мини-проект: всё вместе

Структура:
```
project/
├─ src/app.py
├─ tests/test_app.py
└─ pytest.ini
```

**`src/app.py`**
```python
import asyncio

class API:
    async def get_user(self, uid: int) -> dict:
        await asyncio.sleep(0.03)    # IO
        return {"id": uid, "name": "Alice"}

async def load_profile(api: API, uid: int) -> dict:
    async with asyncio.timeout(0.1):  # не дать запросу повиснуть
        data = await api.get_user(uid)
    return {"id": data["id"], "title": f"User {data['name']}"}
```
Что делает мини-проект. В модуле src/app.py класс API имитирует внешнюю зависимость (сетевой запрос/БД), возвращая словарь пользователя после небольшого asyncio.sleep — это заменитель реального I/O. Функция load_profile — тонкая бизнес-обёртка: она берёт данные пользователя у API, дополнительно форматирует их и возвращает готовую «витрину». Ключевой момент — asyncio.timeout(0.1): мы явно фиксируем SLA вызова к внешнему миру и не допускаем бесконечных зависаний; при превышении лимита наружу полетит asyncio.TimeoutError. Такой контракт времени делает поведение предсказуемым и хорошо тестируемым.

Почему это хороший шаблон. Разделение «границ» (класс API) и «бизнес-логики» (load_profile) упрощает тесты и сопровождение. Граница легко мокается (AsyncMock/patch), а load_profile остаётся чистой — её можно проверять и на «реальной» реализации, и на подменённой. Таймаут локализован внутри «тонкой» функции, поэтому любые деградации внешней зависимости не разрастаются по коду. Дополнительно вы можете дать именованные фоновые задачи, если когда-нибудь решите параллелить несколько внешних вызовов; это улучшит читаемость логов и трейсбеков.

Про тестирование и совместимость. В юнит-тестах обычно есть два кейса: «счастливый путь» с мокнутым API.get_user (быстрый ответ, проверяем формат итога) и негативный — подменяем get_user на «медленный» AsyncMock(side_effect=slow) и ожидаем TimeoutError. Если проект на Python < 3.11, замените контекст на await asyncio.wait_for(api.get_user(uid), timeout=0.1) — семантика та же (внутри произойдёт кооперативная отмена), просто синтаксис другой. На CI полезно включать PYTHONASYNCIODEBUG=1 и иметь автOUSE-фикстуру, которая после теста отменяет и дожидается любых «хвостов» в event loop — это резко снижает флаки.

Расширения и граничные случаи. В реальном сервисе добавьте обработку доменных ошибок: различайте таймаут от «плохих данных» и сетевых исключений; логируйте и, если нужно, считайте метрики (таймауты, доля ошибок, задержки). Если API.get_user иногда возвращает пустые/неполные структуры, load_profile должен валидировать вход (например, проверять наличие name) и решать политику: дефолтные значения, 4xx, повторная попытка. При параллельных обращениях к нескольким ресурсам используйте TaskGroup (3.11+) или gather с локальными таймаутами на каждый шаг и общий дедлайн на весь сценарий — так вы сохраните структурную конкуррентность и избежите «висячих» задач.


**`tests/test_app.py`**
```python
import asyncio
import pytest
from unittest.mock import AsyncMock, patch
from src.app import API, load_profile

@pytest.fixture(autouse=True)
async def _cleanup_tasks():
    yield
    cur = asyncio.current_task()
    pending = [t for t in asyncio.all_tasks() if t is not cur and not t.done()]
    for t in pending:
        t.cancel()
    if pending:
        await asyncio.gather(*pending, return_exceptions=True)

@pytest.mark.asyncio
async def test_load_profile_happy():
    fake = AsyncMock(return_value={"id": 5, "name": "Bob"})
    with patch.object(API, "get_user", fake):
        prof = await load_profile(API(), 5)
        assert prof["title"] == "User Bob"
        fake.assert_awaited_once()

@pytest.mark.asyncio
async def test_load_profile_timeout():
    async def slow(*_a, **_kw):
        await asyncio.sleep(1.0)
    with patch.object(API, "get_user", AsyncMock(side_effect=slow)):
        with pytest.raises(asyncio.TimeoutError):
            await load_profile(API(), 7)
```
Этот тестовый модуль показывает «идеальную связку» для async-кода: изоляцию внешней зависимости через AsyncMock, явные ожидания (assert_awaited*) и уборку фоновых задач после каждого теста. Фикстура с autouse=True проходит по всем задачам текущего event loop, отменяет оставшиеся и дожидается их завершения. Благодаря этому состояния между тестами не протекают: даже если внутри тестируемого кода где-то создалась фоновая корутина и её забыли дождаться/закрыть, фикстура «подметёт» хвосты, и следующий тест стартует с чистого цикла. Это сильно снижает флаки и делает падения воспроизводимыми.

Тест test_load_profile_happy проверяет «счастливый путь» без реального I/O. Мы патчим API.get_user на AsyncMock, который мгновенно возвращает предсказуемые данные. Далее утверждаем бизнес-результат ("User Bob") и то, что зависимость действительно была ожидана. Рекомендуется уточнить аргументы через fake.assert_awaited_once_with(5) — так фиксируется и факт правильного ожидания, и корректный протокол вызова. Такой подход документирует контракт между слоем бизнес-логики и внешним API, а также делает тест быстрым и детерминированным.

Во втором тесте (test_load_profile_timeout) мы проверяем важнейший нештатный сценарий: зависимость «висит» дольше бюджета времени. Подмена get_user на «медленную» корутину через side_effect гарантирует, что локальный таймаут в load_profile сработает и поднимет asyncio.TimeoutError. Это — тест на SLA по времени, а не просто на корректный ответ. Именно на таких сценариях чаще выявляются регрессии: внешние сервисы деградируют, задержки растут, и только явный таймаут не даёт сценарию зависнуть.

Дополнительно имеет смысл обрамлять сами тестовые сценарии верхнеуровневым дедлайном (asyncio.timeout(1)), чтобы любой неожиданный застой превращался в понятный TimeoutError c хорошим трейсом. Если проект поддерживает Python < 3.11, замените использование контекста asyncio.timeout внутри тестируемой функции на asyncio.wait_for — семантика (отмена внутри, TimeoutError снаружи) сохраняется. В остальном структура модуля уже выстроена правильно: изоляция границ моком, проверка и позитивной, и негативной ветки, и чистка event loop — всё это делает набор тестов надёжным в ежедневных прогонах и на CI.


**`pytest.ini`**
```ini
[pytest]
asyncio_mode = auto
```

pytest.ini с asyncio_mode = auto включает «умный» режим плагина pytest-asyncio: он сам создаёт и закрывает event loop там, где видит async def-тесты, поэтому декоратор @pytest.mark.asyncio становится необязательным. Это уменьшает бойлерплейт и снижает риск пропустить маркер на новом тесте. Режим особенно удобен в смешанных наборах, где рядом живут и синхронные, и асинхронные тесты — плагин корректно подхватывает только те кейсы, которым нужен цикл.

Важно понимать границы: «auto» управляет жизненным циклом стандартного asyncio-loop для тестов, но не знает про ваши кастомные циклы/реакторы. Если у вас есть самописные фикстуры, которые вручную создают/закрывают loop, они могут конфликтовать с автоматикой: держите один источник правды (либо авто-режим, либо собственная фабрика цикла). Для стабильности на CI полезно добавить авто-фикстуру, которая после каждого теста отменяет и дожидается «висячих» задач — это дополняет «auto» и гарантирует чистый loop.

Альтернатива — asyncio_mode = strict (в новых версиях плагина). «Строгий» режим усиливает изоляцию и тщательнее проверяет неправильные комбинации (например, попытки использовать чужой loop), но иногда требует подправить старые фикстуры. Если вы только наводите порядок, начните с auto, а на «strict» переходите, когда весь проект следует единым правилам.

Наконец, убедитесь, что конфиг подхватывается именно там, где запускается pytest (корень репозитория или тестового пакета), и что плагин pytest-asyncio установлен. Если проект поддерживает Python < 3.11, не забудьте: конструкция asyncio.timeout(...) недоступна — используйте asyncio.wait_for(...) внутри тестируемого кода, при этом сам режим auto продолжит работать как ожидается.




## Чек-лист для PR и CI
 Включён asyncio_mode = auto или расставлен @pytest.mark.asyncio.
Режим auto делает маркер не обязательным и сам управляет циклом событий, что уменьшает бойлерплейт и риск забыть декоратор в новом тесте. Если по историческим причинам остались собственные фикстуры, создающие loop, убедись, что они не конфликтуют с автоматикой. Для больших репозиториев удобно постепенно мигрировать: новые тесты — на auto, старые — с явным маркером.

 На «узких местах» стоят таймауты (asyncio.timeout(...)) и есть общий дедлайн на сценарий.
Локальные лимиты документируют SLA конкретного шага (HTTP, БД, RPC), а внешний дедлайн превращает любое подвисание в детерминированный TimeoutError. Не забывай про кооперативную отмену: ресурсы закрываются в finally внутри шагов. На Python < 3.11 используй asyncio.wait_for как эквивалент.

 Фоновые задачи именованы и/или завершаются авто-фикстурой уборки.
Имена задач (create_task(..., name="bg:...")) делают трейс читаемым. Авто-фикстура после yield собирает «висяки» через asyncio.all_tasks(), вызывает cancel() и ждёт их завершения (через gather(..., return_exceptions=True), по возможности с wait_for-страховкой). Это исключает протечки состояния между тестами и редкие флаки.

 Внешние зависимости изолированы моками: AsyncMock + проверки assert_awaited*.
Патчи ставь в месте использования, а не объявления. Для асинхронных API проверяй именно факт ожидания (assert_awaited_once_with, assert_has_awaits) — это ловит типичные ошибки «забыли await». Для реалистичности используй side_effect (исключения, задержки, чередование ответов) и, при необходимости, spec/spec_set, чтобы тест падал при опечатках в методах.

 Очереди корректно дренируются: task_done() на каждый get() и ожидание queue.join().
Забытый task_done() превращает тест в «вечный». Оборачивай обработку элемента в try/finally, чтобы task_done() сработал даже при исключении. Для нескольких потребителей добавляй столько же «сентинелов» (например, None), сколько консьюмеров, или отменяй их после join() и дожидайся отмены.

 Используется структурная конкуррентность (TaskGroup, 3.11+) вместо «ручного» менеджмента задач.
При падении одной подзадачи соседние автоматически отменяются, а наружу выбрасывается ExceptionGroup, который можно обрабатывать через except*. Это резко снижает риск «висячих» тасков и упрощает код. На 3.10 и ниже — аккуратно эмулируй поведение через gather + явную отмену оставшихся задач.

Глобальный защитный дедлайн на тест-кейс.
Обрамляй тело теста верхним asyncio.timeout(...) (например, 1–2 секунды): любой неожиданный застой превратится в понятный TimeoutError с чистым трейсом.

 Детерминизм: время/рандом под контролем.
Фиксируй seed RNG и, где уместно, «замораживай» время в тестах. Это снижает флаки от ретраев/backoff и тайминговых окон.

 Диагностика: логи/метрики как часть ассертов.
Через caplog/capfd проверяй, что таймаут/отмена действительно зафиксированы системой, а предупреждений нет. Это помогает отличать «правильный фейл» от «тихой деградации».

 Конкурентный запуск без конфликтов.
Если используешь xdist, следи, чтобы порты/временные директории/переменные окружения не пересекались между воркерами (уникальные префиксы, фикстуры с tmp_path_factory).

 Режим отладки asyncio на CI.
Включай PYTHONASYNCIODEBUG=1 (или loop.set_debug(True)) в CI-джобах для ловли «забытых await» и долгих колбэков; это экономит часы на расследованиях «иногда краснеет».
---

# Тестирование асинхронного кода (дополнение)

Ниже — расширенное руководство **строго по темам**:
- `pytest-asyncio` и `IsolatedAsyncioTestCase`
- Моки и патчи для `async`-функций
- Контроль и поиск «висячих» задач

## 1) pytest-asyncio и IsolatedAsyncioTestCase

### 1.1 pytest-asyncio: как запускать и не зависать
```python
# tests/test_user_service.py
import asyncio
import pytest

async def fetch_user(uid: int) -> dict:
    await asyncio.sleep(0.01)
    return {"id": uid, "name": "Ada"}

@pytest.mark.asyncio
async def test_fetch_user_ok():
    data = await fetch_user(1)
    assert data["name"] == "Ada"
```


Этот тест — минимальный пример того, как с pytest-asyncio запускать корутину как обычный тест. Декоратор @pytest.mark.asyncio сообщает PyTest, что внутри — async def, и плагин создаёт event loop, в котором корутина выполняется. Сам тест вызывает fetch_user(1), дожидается результата и проверяет бизнес-инвариант: в полученном словаре поле name равно "Ada". Такой шаблон хорош тем, что отделяет «что мы проверяем» (значение поля) от «как это вычисляется» (асинхронное ожидание).

Семантически await asyncio.sleep(0.01) имитирует I/O — сетевой запрос, доступ к БД или файловой системе. Это важно для структуры тестов: вы отрабатываете асинхронный путь (планировщик, await-пункты), не завися от реальной сети. В боевом коде «сон» будет заменён настоящим I/O, а тесты останутся прежними. Если далее вы оборачиваете такие вызовы таймаутами в продуктивном коде, имеет смысл добавить и тест на таймаут, подменив зависимость на «медленную» корутину — так вы тестируете не только корректность результата, но и соблюдение SLA по времени.

Чтобы тесты оставались детерминированными в больших наборах, полезно избегать реального I/O и вводить чёткие правила изоляции. Для юнит-уровня — использовать моки на границах (HTTP/БД), а ассерты строить вокруг возвращаемой структуры и вызовов (assert_awaited* для AsyncMock). Если тестов много, удобнее включить asyncio_mode = auto в pytest.ini: плагин сам подхватит async def-тесты без декоратора, снизится бойлерплейт, и вы не забудете пометить новый тест.

Наконец, подумайте о страховке от подвисаний: на Python 3.11+ можно обрамлять критические шаги в asyncio.timeout(...), превращая любой «застой» в понятный TimeoutError. На CI полезно держать автOUSE-фикстуру, которая после каждого теста отменяет и дожидается всех фоновых задач (asyncio.all_tasks() → cancel() → gather(...)). Эти простые практики делают асинхронные тесты предсказуемыми, быстрыми и устойчивыми даже при параллельном запуске.

**Почему так:** без маркера `@pytest.mark.asyncio` (или без `asyncio_mode=auto` в `pytest.ini`) PyTest не выполнит `async def` как корутину.

**Таймауты на шаги и сценарий**
```python
import asyncio
import pytest

@pytest.mark.asyncio
async def test_with_timeout():
    # локальный лимит на шаг
    async with asyncio.timeout(0.05):
        await asyncio.sleep(0.01)
    # общий дедлайн на сценарий
    async with asyncio.timeout(0.1):
        await asyncio.sleep(0.05)
```
Этот тест демонстрирует два уровня контроля времени: «локальный» таймаут для конкретного шага и «глобальный» дедлайн для всего сценария. В первом блоке мы гарантируем, что потенциально рискованная операция (здесь — имитация I/O через sleep) не выйдет за пределы 50 мс; во втором — что суммарное выполнение оставшейся логики уложится в 100 мс. Такая вложенная схема делает диагностику прозрачной: если падает внутренний контекст, значит деградировал конкретный шаг; если срабатывает внешний — у сценария в целом недостаточный бюджет.

Важно помнить о том, как asyncio.timeout работает семантически: при превышении лимита внутрь выполняющейся корутины вбрасывается CancelledError в ближайшей точке await, а снаружи вы увидите asyncio.TimeoutError. Отмена в asyncio кооперативная — значит, ресурсы нужно закрывать в finally внутри операции (закрыть HTTP-сессию, файл, отменить ретраи), а не надеяться на внешние «подмётки». Если в шаге есть собственные под-задачи, они тоже должны корректно реагировать на отмену, иначе получите «висящие» таски и флаки на последующих тестах.

Выбор значений таймаутов должен быть реалистичным и мотивированным метриками: ориентируйтесь на p95/p99 для окружения CI, добавляйте небольшой запас против джиттера планировщика и соседних задач. Хорошая практика — параллельно с таймаутом утверждать и эффект (лог/метрику о таймауте), чтобы отличать «правильный» фейл по времени от тихой деградации. Также полезно давать имена задачам в тестируемом коде и включать отладку asyncio на CI (PYTHONASYNCIODEBUG=1), чтобы быстро ловить забытые await и долгие колбэки.

Наконец, учитывайте версию Python. Контекст-менеджер asyncio.timeout доступен с 3.11 и прекрасно вкладывается друг в друга; на 3.10 и ниже используйте эквивалент asyncio.wait_for, просто синтаксис будет менее наглядным (придётся оборачивать каждую корутину отдельно). Независимо от версии, сам паттерн остаётся тем же: локальные лимиты на узкие места + общий дедлайн на кейс, с обязательной очисткой ресурсов и явной реакцией на превышение бюджета.

- Внутри длительной корутины поднимется `CancelledError` → освободите ресурсы в `finally`.
- Снаружи увидите `asyncio.TimeoutError` → тест корректно «проваливается», не зависая.

**Практика:**
- Маркируйте только те тесты, что *действительно* async — смешанные наборы тестов читаются проще.
- Давайте понятные имена задачам: `asyncio.create_task(fn(), name="bg:preload-cache")` — отладка проще.

### 1.2 IsolatedAsyncioTestCase (unittest-стиль)
```python
# tests/test_mailer_unittest.py
import asyncio
from unittest import IsolatedAsyncioTestCase

class TestMailer(IsolatedAsyncioTestCase):
    async def test_send(self):
        async def send():
            await asyncio.sleep(0.01)
            return True
        self.assertTrue(await send())

    async def test_with_timeout(self):
        with self.assertRaises(asyncio.TimeoutError):
            async with asyncio.timeout(0.01):
                await asyncio.sleep(0.1)
```
Этот пример показывает «чистый» подход к асинхронным тестам в экосистеме unittest. Наследование от IsolatedAsyncioTestCase создаёт отдельный event loop на каждый метод, поэтому фоновые задачи, таймауты и отмены из одного теста не влияют на другой. В методе test_send мы эмулируем асинхронную операцию через await asyncio.sleep(0.01) и проверяем бизнес-инвариант (True). Такой шаблон удобен для больших кодовых баз, где уже много классовых тестов и важно сохранить привычные assert*, иерархию базовых классов и хуки.

Во втором тесте (test_with_timeout) демонстрируется правильный способ фиксировать SLA по времени. Контекст asyncio.timeout(0.01) (Python 3.11+) превращает потенциальное зависание в детерминированный TimeoutError, а self.assertRaises(...) делает ожидание таймаута частью спецификации теста. Важно понимать семантику: при превышении лимита внутрь выполняющейся корутины вбрасывается CancelledError на ближайшем await, поэтому освобождение ресурсов (закрытие сессий/файлов, остановка ретраев) нужно делать в finally внутри тестируемой операции. Снаружи вы видите уже преобразованный TimeoutError, что делает диагностику понятной.

Практические рекомендации: используйте asyncSetUp/asyncTearDown для открытия/закрытия асинхронных ресурсов (HTTP-сессий, подключений к БД) — так они живут ровно в границах теста и не «подтекают». Если внутри тестируемого кода создаются фоновые задачи, давайте им имена (create_task(..., name="...")) и проверяйте корректную отмену в отдельных кейсах; это сильно упрощает отладку. На CI имеет смысл включать отладку asyncio (PYTHONASYNCIODEBUG=1) — она помогает ловить «забытые await» и долго выполняющиеся колбэки.

Совместимость: если вы поддерживаете Python < 3.11, замените asyncio.timeout(...) на эквивалент await asyncio.wait_for(coro, timeout=...) — поведение с точки зрения теста останется тем же (отмена внутри, TimeoutError снаружи). При желании можно добавить «верхний» дедлайн на весь тест (например, через wait_for вокруг общей корутины), чтобы любой неожиданный застой превращался в понятную ошибку времени. Такой набор практик делает асинхронные юнит-тесты предсказуемыми, быстрыми и устойчивыми в ежедневных прогонах.

**Когда использовать:** у вас уже много `unittest`-тестов, важны привычные `assert*` и хуки `setUp/tearDown`.

---

## 2) Моки и патчи для async-функций

### 2.1 AsyncMock для методов/функций
```python
# tests/test_profile_mock.py
import pytest
from unittest.mock import AsyncMock, patch

class Client:
    async def get_user(self, uid: int) -> dict: ...

async def load_user(client: Client, uid: int) -> str:
    return (await client.get_user(uid))["name"]

@pytest.mark.asyncio
async def test_load_user_with_mock():
    fake = AsyncMock(return_value={"id": 7, "name": "Linus"})
    with patch.object(Client, "get_user", fake):
        name = await load_user(Client(), 7)
        assert name == "Linus"
        fake.assert_awaited_once_with(7)
```
Этот тест иллюстрирует классический юнит-подход: внешняя зависимость (метод Client.get_user) полностью изолируется с помощью AsyncMock, а мы проверяем только бизнес-логику функции load_user. Мок возвращает детерминированные данные ({"id": 7, "name": "Linus"}), благодаря чему тест быстрый, воспроизводимый и не зависит от сети/БД. Ключевой момент — проверка именно асинхронного контракта: fake.assert_awaited_once_with(7) подтверждает, что метод не просто вызвали, а дождались его результата с ожидаемым аргументом.

Контекст with patch.object(Client, "get_user", fake): подменяет метод на время блока и автоматически восстанавливает исходное состояние по выходу — это предотвращает «протечки» между тестами. В реальном проекте патчить следует «в месте использования»: если тестируемый модуль импортирует Client из service, то подмена должна быть на service.Client.get_user, иначе вызов пройдёт мимо мока. Для дополнительной страховки от опечаток и изменения интерфейса можно включить спецификацию: spec=True/spec_set=True, чтобы мок не позволил вызвать несуществующий атрибут.

Ещё одна сильная сторона AsyncMock — управляемые сценарии через side_effect: можно эмулировать задержку, исключение или последовательность разных ответов (успех → ошибка → успех) и тем самым проверить обработку таймаутов, ретраев, логирования. Если в коде есть SLA по времени, имеет смысл добавить отдельный тест, где side_effect — «медленная» корутина, и ожидать TimeoutError на верхнем уровне (через asyncio.timeout в самом коде или wait_for в тесте для Python < 3.11). Так вы покрываете не только «счастливый путь», но и критичные нештатные ветки.

Наконец, чтобы поддерживать читаемость и устойчивость набора тестов, сохраняйте единый стиль проверок: для асинхронных зависимостей — только assert_awaited*, для порядка/количества вызовов — assert_has_awaits/reset_mock() между этапами. Комбинация детерминированного мока, правильной области патча и явных ассертов по ожиданию делает такие тесты надёжными на CI и быстро объяснимыми при падениях: если что-то идёт не так, вы видите где именно нарушен контракт — в данных, аргументах или самом ожидании.


**Заметки:**
- `AsyncMock` корректно поддерживает `await`, считает ожидания, сохраняет сигнатуру вызовов.
- Проверяйте *и* что вызвали (`assert_awaited_with`), *и* сколько раз (`assert_awaited_once`).

### 2.2 Мок асинхронного контекст-менеджера (например, aiohttp)
```python
# tests/test_aiohttp_like.py
from types import SimpleNamespace
from unittest.mock import AsyncMock, Mock
import pytest

@pytest.mark.asyncio
async def test_aiohttp_like_context_manager():
    response = SimpleNamespace(json=AsyncMock(return_value={"ok": True}))
    cm = SimpleNamespace(
        __aenter__=AsyncMock(return_value=response),
        __aexit__=AsyncMock(return_value=None),
    )
    # get возвращает контекст-менеджер синхронно (без await)
    session = SimpleNamespace(get=Mock(return_value=cm))

    async with session.get("http://example") as resp:
        data = await resp.json()

    assert data["ok"] is True
    session.get.assert_called_once_with("http://example")
    cm.__aenter__.assert_awaited_once()
    cm.__aexit__.assert_awaited_once()
    response.json.assert_awaited_once()
```
Изначальный фрагмент не запускался по двум причинам: во-первых, на верхнем уровне файла нельзя писать await — нужен async-контекст (например, тестовая корутина под @pytest.mark.asyncio). Во-вторых, вы делали session.get(...).__aenter__() у объекта, который возвращает AsyncMock: у корутины нет __aenter__, поэтому обращение падает. В «aiohttp-подобном» API session.get(url) возвращает контекст-менеджер синхронно; «await» происходит на его __aenter__/__aexit__ и на методах ответа (json()/text()).

Правильная модель такова: session.get(...) — обычный вызов, который сразу отдаёт объект-контекстник (его можно смоделировать Mock(return_value=cm)), у cm есть асинхронные __aenter__/__aexit__ (это AsyncMock), а «ответ» (resp) имеет асинхронные методы (json = AsyncMock(...)). Тогда тест пишется естественно: async with session.get(url) as resp: data = await resp.json(). В проверках уместно утверждать, что get был вызван (не «ожидался»), а __aenter__, __aexit__ и resp.json() — именно ожидались: assert_called_once_with(url) для get и assert_awaited_once() для асинхронных точек.

Ещё один частый подводный камень — «перемок» уровней: если случайно сделать session.get = AsyncMock(...), но продолжать использовать async with session.get(...), вы вынуждены писать await session.get(...) прежде чем войти в контекст, что уже не соответствует контракту aiohttp. Поэтому для правдоподобной имитации возвращайте контекстник синхронно (Mock), а не как корутину. Дополнительно можно включить spec/spec_set, чтобы мок ругался на несуществующие атрибуты, и покрыть альтернативные ветки: ошибка при входе в контекст (__aenter__ бросает исключение), битый JSON (исключение в json()), задержки через side_effect — такие сценарии проверяют корректное освобождение ресурсов и реакцию на ошибки.

Наконец, не забывайте про область патча: в реальном проекте подменять нужно там, где объект используется (модуль, который импортирует session), иначе вызов пройдёт мимо мока. Имена на моки/контекст-менеджер/ответ помогают быстро разбираться в логах и отчётах, а отдельная авто-фикстура уборки «висящих» задач после теста удержит event loop в чистоте, если внутри тестируемого кода создаются фоновые корутины. Такой набор практик делает тесты на асинхронные HTTP-вызовы быстрыми, детерминированными и максимально близкими к реальному контракту клиента.

**Идея:** у async-контекст-менеджера должны быть `__aenter__`/`__aexit__`, которые тоже асинхронные.

### 2.3 Проверяем таймаут через «медленный» мок
```python
# tests/test_timeout_patch.py
import asyncio
import types
import pytest
from unittest.mock import AsyncMock, patch

# "Зависимость", которую будем патчить
api = types.SimpleNamespace()

async def _real_get_user(uid: int) -> dict:
    await asyncio.sleep(0.001)
    return {"id": uid}

api.get_user = _real_get_user

# Код под тестом: оборачиваем вызов таймаутом
async def fetch_with_timeout(uid: int) -> dict:
    async with asyncio.timeout(0.05):  # Python 3.11+
        return await api.get_user(uid)

@pytest.mark.asyncio
async def test_timeout_on_slow_call():
    async def slow(_uid: int):
        await asyncio.sleep(1.0)  # заведомо дольше лимита

    # Патчим ТАМ, ГДЕ ИСПОЛЬЗУЕТСЯ
    with patch(__name__ + ".api.get_user", AsyncMock(side_effect=slow)):
        with pytest.raises(asyncio.TimeoutError):
            await fetch_with_timeout(42)

Этот тест демонстрирует проверку SLA по времени для асинхронной зависимости: мы целенаправленно превращаем вызов get_user в «медленный» (side_effect=slow) и ожидаем, что обёртка с таймаутом завершит сценарий предсказуемым asyncio.TimeoutError. Такая проверка важнее банального «счастливого пути»: именно деградации внешних сервисов и рост задержек чаще всего приводят к подвисаниям в проде. Тест формализует контракт: «если операция занимает > 50 мс — это ошибка времени, а не бесконционное ожидание».

Ключевой момент — патч «в месте использования». Подменять нужно ту ссылку на функцию, которой реально пользуется тестируемый код, а не её оригинальное определение где-то в другом модуле. Иначе вызов обойдёт мок и тест станет ложно зелёным. AsyncMock выбран не случайно: он корректно поддерживает семантику await и может имитировать не только возврат значения, но и задержки/исключения через side_effect. Это делает сценарий реалистичным: отмена в asyncio кооперативная и всплывает в ближайшей точке await внутри «медленной» функции.

Важно понимать семантику asyncio.timeout (Python 3.11+): при превышении лимита изнутри поднимается CancelledError, а снаружи вы видите TimeoutError. Поэтому освобождение ресурсов (закрытие сессий, файлов, отмена ретраев) должно происходить в finally внутри операции — тест проверяет, что внешняя логика правильно реагирует на превышение бюджета. Если вы на Python < 3.11, используйте эквивалент asyncio.wait_for(...): поведение с точки зрения теста то же самое, просто синтаксис другой и хуже вкладывается.

Чтобы повысить надёжность, добавьте вспомогательные утверждения: лог о таймауте (через caplog), отсутствие повторных несогласованных вызовов зависимости, счётчики assert_awaited* для подтверждения протокола ожидания. На CI полезно иметь «верхний» дедлайн на сам тест, чтобы любой неожиданный застой превращался в читаемый TimeoutError, и автофикстуру, которая после теста отменяет и дожидается всех «висячих» задач. В результате такой тест не только ловит зависания, но и документирует временные ожидания системы, делая сбои объяснимыми и быстро исправляемыми.

```
**Правило:** если в коде нет явного таймаута — напишите тест, который гарантирует его наличие.

---

## 3) Контроль и поиск «висячих» задач

### 3.1 Структурная конкуррентность (`TaskGroup`)
```python
import asyncio

async def worker(x: int) -> int:
    await asyncio.sleep(0.01)   # имитация работы
    return x * 2

async def process_batch(items):
    results = []

    async def one(it):
        results.append(await worker(it))

    async with asyncio.TaskGroup() as tg:
        for it in items:
            tg.create_task(one(it))

    return results
```
Этот фрагмент опирается на структурную конкуррентность в asyncio (Python 3.11+): блок async with asyncio.TaskGroup() объявляет область жизни связанных подзадач. Все задачи, созданные через tg.create_task(...), принадлежат группе и гарантированно завершаются/отменяются до выхода из контекста. Это устраняет классический источник «висячих» задач: либо весь набор шагов успешно доходит до конца, либо при первой необработанной ошибке группа сворачивается целиком.

Если вам нужны результаты работы воркеров, их надо явно собирать — TaskGroup не возвращает значения автоматически. Два распространённых приёма: (1) копить результаты внутри вложенной корутины (например, results.append(await worker(it))) и вернуть список после выхода из контекста; (2) сохранить созданные Task в список и прочитать t.result() уже после выхода — к этому моменту они завершены (или отменены). Первый вариант проще, второй даёт больше контроля (можно привязать задачи к исходным элементам, логировать имена и т.д.).

Поведение при ошибках отличается от «ручного» менеджмента: падение одной подзадачи автоматически отменяет остальные и поднимает наружу ExceptionGroup, который удобно разбирать через except* по типам исключений. Это делает обработку сбоев явной и упорядоченной. Дополнительно полезно давать имена задачам (tg.create_task(worker(it), name=f"worker[{it}]")) — трассировки и логи становятся читаемее; а для долгих шагов разумно навешивать локальные таймауты (asyncio.timeout(...)) и выполнять очистку ресурсов в finally, чтобы отмена (которая в asyncio кооперативная) проходила корректно.

**Зачем:** если одна подзадача падает — `TaskGroup` отменяет остальные. Меньше «хвостов», меньше утечек.

### 3.2 Жёсткие таймауты на шаги и весь сценарий
```python
# tests/test_pipeline_finishes.py
import asyncio
import pytest

async def maybe_slow_io():
    # имитация «сетевого» шага, должен уложиться в 50 мс
    await asyncio.sleep(0.01)

async def rest_of_pipeline():
    # остальная часть конвейера
    await asyncio.sleep(0.02)

@pytest.mark.asyncio
async def test_pipeline_finishes():
    try:
        async with asyncio.timeout(0.2):       # общий дедлайн
            async with asyncio.timeout(0.05):  # «сетевой» шаг
                await maybe_slow_io()
            await rest_of_pipeline()
    except asyncio.TimeoutError:
        pytest.fail("pipeline exceeded time budget")
```
Этот тест иллюстрирует «матрёшку» таймаутов: локальный лимит на рискованный шаг (сетевой/I/O) и общий дедлайн на весь сценарий. Такой шаблон даёт прозрачную диагностику: если падает внутренний таймаут — деградировал конкретный шаг; если срабатывает внешний — сценарий в целом не уложился в бюджет. Важно, чтобы maybe_slow_io() и rest_of_pipeline() были определены, а pytest импортирован на уровне модуля, иначе декоратор @pytest.mark.asyncio упадёт при импорте.

Семантика asyncio.timeout (Python 3.11+): при превышении лимита внутрь корутины вбрасывается CancelledError, а наружу тест получает asyncio.TimeoutError. Поэтому освобождение ресурсов (закрытие HTTP-сессий/файлов, остановка ретраев) нужно делать в finally внутри шагов. Для совместимости с Python < 3.11 используйте эквивалент asyncio.wait_for(...) на каждом await. Полезно держать в сьюте оба сценария: «успех в пределах лимитов» и «искусственно медленный шаг» с ожиданием TimeoutError — это документирует SLA и ловит регрессии по времени.

**Паттерн:** «матрёшка» из таймаутов показывает, *какой именно* шаг превысил бюджет времени.

### 3.3 Очереди `asyncio.Queue`: `task_done()` и `join()`
```python
# tests/test_queue_drains.py
import asyncio
import pytest
from asyncio import Queue

async def handle(item: int) -> None:
    # имитация обработки элемента
    await asyncio.sleep(0.001)

async def _consumer(q: Queue):
    while True:
        item = await q.get()
        try:
            await handle(item)
        finally:
            q.task_done()

@pytest.mark.asyncio
async def test_queue_drains():
    q = Queue()
    consumer = asyncio.create_task(_consumer(q), name="bg:consumer")

    for i in range(3):
        await q.put(i)

    # ждём, пока очередь полностью «осушится»
    await q.join()

    # мягко останавливаем фонового потребителя и убеждаемся, что отмена дошла
    consumer.cancel()
    with pytest.raises(asyncio.CancelledError):
        await consumer

Этот тест проверяет правильный дренаж очереди и «чистое» завершение фонового потребителя. Ключевая инварианта asyncio.Queue: счётчик «необработанных» элементов увеличивается на каждом put() и уменьшается только вызовом task_done(). Поэтому обработчик обязан вызывать task_done() в finally, чтобы счётчик уменьшался даже при исключениях — иначе await q.join() никогда не вернётся, и тест зависнет. Схема «положили 3 элемента → дождались q.join()» гарантирует, что все элементы действительно прошли через handle.

После того как очередь осушена, важно корректно завершить бесконечный потребитель. Самый простой способ в тесте — consumer.cancel() и затем await consumer с утверждением CancelledError: так вы убеждаетесь, что отмена дошла и задача не осталась «висеть». Альтернатива для прод-кода — «сентинелы» (например, None) на каждого потребителя: они позволяют выйти без исключений. В обоих случаях порядок важен: сначала q.join() (гарантия, что ничего не потеряно), потом остановка потребителей, чтобы оставить event loop в чистом состоянии и избежать флаки на последующих тестах.
```
**Если забыть `task_done()`**, `join()` не вернёт управление и тест «зависнет».

### 3.4 Автоматическая уборка «висячих» задач (фикстура)
```python
# conftest.py
import asyncio
import pytest

@pytest.fixture(autouse=True)
async def _cancel_pending_tasks():
    yield  # тест выполняется здесь
    cur = asyncio.current_task()
    pending = [t for t in asyncio.all_tasks() if t is not cur and not t.done()]
    for t in pending:
        t.cancel()
    if pending:
        await asyncio.gather(*pending, return_exceptions=True)
```

Эта автOUSE-фикстура решает типовую проблему async-тестов: «висячие» фоновые задачи, которые переживают завершение кейса и случайно влияют на следующий. После yield она получает управление, собирает все задачи текущего event loop (asyncio.all_tasks()), исключает саму фикстуру и уже завершённые, и отправляет оставшимся cancel(). Важно, что она не останавливается на этом, а ждёт завершения отменённых задач через asyncio.gather(..., return_exceptions=True): отмена в asyncio кооперативная, и без ожидания не сработают finally-блоки, не закроются соединения и файлы.

Такой «подметающий» слой делает тесты детерминированными: состояние цикла обнуляется между кейсами, исчезают редкие флаки из-за фоновых ретраев, слушателей и таймеров. Фикстура особенно полезна в связке с параллельным прогоном (xdist) и режимом asyncio_mode = auto, где у каждого теста свой loop. Если в проекте принято именовать задачи (create_task(..., name="...")), диагностика становится ещё проще — по логам видно, кто именно мешает уборке.

Из практических нюансов: полезно обрамлять gather внешним wait_for с небольшим лимитом (например, 0.5–1.0 с), чтобы фикстура не зависала, если какая-то задача некорректно игнорирует отмену или крутится в CPU-цикле. В таком случае можно залогировать «упрямых» исполнителей и упасть явным фейлом в конце теста/джоба. И помните: эта фикстура — последняя линия обороны, но не замена дисциплине; внутри самих тестов и кода всё равно ставьте локальные таймауты, корректно обрабатывайте CancelledError в finally и закрывайте ресурсы там, где они открываются.

**Зачем это нужно:** отмена в `asyncio` кооперативная — нужно *дождаться* отменённых задач, иначе они уйдут в следующий тест.

---

## 4) Мини-рикэп и чек-лист
Каждый пункт чек-листа — это не «совет вообще», а конкретная страховка от типичных багов async-тестов. Режим asyncio_mode=auto (или явный @pytest.mark.asyncio) гарантирует корректный жизненный цикл event loop для каждого теста. Это снимает сразу два класса проблем: забытые маркеры на новых тестах и «протечки» состояния цикла между кейсами. Если в проекте есть свои фабрики цикла/рантаймы — выберите один механизм управления loop и придерживайтесь его последовательно.

Таймауты должны быть двух уровней: локальные вокруг рискованных шагов (HTTP, БД, RPC, парсинг/сериализация) и общий дедлайн на сценарий. Такой «матрёшкой» вы превращаете зависания в детерминированные падения и сразу видите, где именно сломалось: в узком месте или в общем бюджете. Помните, что отмена в asyncio кооперативная: освобождение ресурсов делайте в finally внутри операций; снаружи вы видите уже TimeoutError.

Моки — не просто ускорение тестов, это фиксация контракта. Для async-зависимостей используйте AsyncMock и проверяйте именно факты ожидания (assert_awaited*), а не только вызова — так ловятся случаи «забыли await». Реалистичность повышают side_effect (задержки, исключения, серии ответов) и spec/spec_set для ловли опечаток в API. Для очередей держите баланс put → get → task_done() и всегда ждите queue.join(); забытый task_done() — частая причина «вечного» теста. Завершение потребителей делайте явно: либо cancel() + ожидание, либо «сентинелы» на каждого консьюмера.

Фоновые «хвосты» убирайте фикстурой: после теста собрать asyncio.all_tasks(), отменить, дождаться с gather(..., return_exceptions=True) и, по возможности, обрамить wait_for, чтобы уборка сама не зависла. На 3.11+ по возможности используйте TaskGroup: при падении одной задачи соседи отменяются автоматически, а ошибки приходят в виде ExceptionGroup, который удобно разбирать через except*. Наконец, на CI добавьте глобальный дедлайн на тест, фиксируйте seed RNG/время и включайте PYTHONASYNCIODEBUG=1 — это даёт детерминизм и быстрые, объяснимые падения, когда что-то пошло не так.
